{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4bc57e76-2352-445d-9960-028a9dc876a7",
   "metadata": {},
   "source": [
    "This loader fetches the text transcript of Youtube videos using the youtube_transcript_api Python package.\n",
    "\n",
    "https://llamahub.ai/l/youtube_transcript\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57d717e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6b3731e",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/home/sankar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21a329c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mpath = \"/home/sankar/Downloads/mistral-7b-openorca.Q5_K_M.gguf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5332f785-40ca-4c0e-9da4-274805a6f685",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import (\n",
    "    SimpleDirectoryReader,\n",
    "    VectorStoreIndex,\n",
    "    ServiceContext,\n",
    ")\n",
    "from llama_index.llms import LlamaCPP\n",
    "from llama_index.llms.llama_utils import (\n",
    "    messages_to_prompt,\n",
    "    completion_to_prompt,\n",
    ")\n",
    "from llama_index.readers import YoutubeTranscriptReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39839014",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ggml_init_cublas: GGML_CUDA_FORCE_MMQ:   no\n",
      "ggml_init_cublas: CUDA_USE_TENSOR_CORES: yes\n",
      "ggml_init_cublas: found 1 CUDA devices:\n",
      "  Device 0: NVIDIA GeForce GTX 1080 Ti, compute capability 6.1\n",
      "llama_model_loader: loaded meta data with 20 key-value pairs and 291 tensors from /home/sankar/Downloads/mistral-7b-openorca.Q5_K_M.gguf (version GGUF V2)\n",
      "llama_model_loader: - tensor    0:                token_embd.weight q5_K     [  4096, 32002,     1,     1 ]\n",
      "llama_model_loader: - tensor    1:              blk.0.attn_q.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor    2:              blk.0.attn_k.weight q5_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor    3:              blk.0.attn_v.weight q6_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor    4:         blk.0.attn_output.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor    5:            blk.0.ffn_gate.weight q5_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor    6:              blk.0.ffn_up.weight q5_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor    7:            blk.0.ffn_down.weight q6_K     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor    8:           blk.0.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor    9:            blk.0.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   10:              blk.1.attn_q.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   11:              blk.1.attn_k.weight q5_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   12:              blk.1.attn_v.weight q6_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   13:         blk.1.attn_output.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   14:            blk.1.ffn_gate.weight q5_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   15:              blk.1.ffn_up.weight q5_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   16:            blk.1.ffn_down.weight q6_K     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   17:           blk.1.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   18:            blk.1.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   19:              blk.2.attn_q.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   20:              blk.2.attn_k.weight q5_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   21:              blk.2.attn_v.weight q6_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   22:         blk.2.attn_output.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   23:            blk.2.ffn_gate.weight q5_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   24:              blk.2.ffn_up.weight q5_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   25:            blk.2.ffn_down.weight q6_K     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   26:           blk.2.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   27:            blk.2.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   28:              blk.3.attn_q.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   29:              blk.3.attn_k.weight q5_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   30:              blk.3.attn_v.weight q6_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   31:         blk.3.attn_output.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   32:            blk.3.ffn_gate.weight q5_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   33:              blk.3.ffn_up.weight q5_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   34:            blk.3.ffn_down.weight q6_K     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   35:           blk.3.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   36:            blk.3.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   37:              blk.4.attn_q.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   38:              blk.4.attn_k.weight q5_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   39:              blk.4.attn_v.weight q5_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   40:         blk.4.attn_output.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   41:            blk.4.ffn_gate.weight q5_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   42:              blk.4.ffn_up.weight q5_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   43:            blk.4.ffn_down.weight q5_K     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   44:           blk.4.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   45:            blk.4.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   46:              blk.5.attn_q.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   47:              blk.5.attn_k.weight q5_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   48:              blk.5.attn_v.weight q5_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   49:         blk.5.attn_output.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   50:            blk.5.ffn_gate.weight q5_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   51:              blk.5.ffn_up.weight q5_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   52:            blk.5.ffn_down.weight q5_K     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   53:           blk.5.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   54:            blk.5.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   55:              blk.6.attn_q.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   56:              blk.6.attn_k.weight q5_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   57:              blk.6.attn_v.weight q6_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   58:         blk.6.attn_output.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   59:            blk.6.ffn_gate.weight q5_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   60:              blk.6.ffn_up.weight q5_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   61:            blk.6.ffn_down.weight q6_K     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   62:           blk.6.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   63:            blk.6.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   64:              blk.7.attn_q.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   65:              blk.7.attn_k.weight q5_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   66:              blk.7.attn_v.weight q5_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   67:         blk.7.attn_output.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   68:            blk.7.ffn_gate.weight q5_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   69:              blk.7.ffn_up.weight q5_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   70:            blk.7.ffn_down.weight q5_K     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   71:           blk.7.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   72:            blk.7.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   73:              blk.8.attn_q.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   74:              blk.8.attn_k.weight q5_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   75:              blk.8.attn_v.weight q5_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   76:         blk.8.attn_output.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   77:            blk.8.ffn_gate.weight q5_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   78:              blk.8.ffn_up.weight q5_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   79:            blk.8.ffn_down.weight q5_K     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   80:           blk.8.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   81:            blk.8.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   82:              blk.9.attn_q.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   83:              blk.9.attn_k.weight q5_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   84:              blk.9.attn_v.weight q6_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   85:         blk.9.attn_output.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   86:            blk.9.ffn_gate.weight q5_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   87:              blk.9.ffn_up.weight q5_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   88:            blk.9.ffn_down.weight q6_K     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   89:           blk.9.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   90:            blk.9.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   91:             blk.10.attn_q.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   92:             blk.10.attn_k.weight q5_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   93:             blk.10.attn_v.weight q5_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   94:        blk.10.attn_output.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   95:           blk.10.ffn_gate.weight q5_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   96:             blk.10.ffn_up.weight q5_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   97:           blk.10.ffn_down.weight q5_K     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   98:          blk.10.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   99:           blk.10.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  100:             blk.11.attn_q.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  101:             blk.11.attn_k.weight q5_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  102:             blk.11.attn_v.weight q5_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  103:        blk.11.attn_output.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  104:           blk.11.ffn_gate.weight q5_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  105:             blk.11.ffn_up.weight q5_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  106:           blk.11.ffn_down.weight q5_K     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  107:          blk.11.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  108:           blk.11.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  109:             blk.12.attn_q.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  110:             blk.12.attn_k.weight q5_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  111:             blk.12.attn_v.weight q6_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  112:        blk.12.attn_output.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  113:           blk.12.ffn_gate.weight q5_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  114:             blk.12.ffn_up.weight q5_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  115:           blk.12.ffn_down.weight q6_K     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  116:          blk.12.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  117:           blk.12.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  118:             blk.13.attn_q.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  119:             blk.13.attn_k.weight q5_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  120:             blk.13.attn_v.weight q5_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  121:        blk.13.attn_output.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  122:           blk.13.ffn_gate.weight q5_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  123:             blk.13.ffn_up.weight q5_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  124:           blk.13.ffn_down.weight q5_K     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  125:          blk.13.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  126:           blk.13.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  127:             blk.14.attn_q.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  128:             blk.14.attn_k.weight q5_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  129:             blk.14.attn_v.weight q5_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  130:        blk.14.attn_output.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  131:           blk.14.ffn_gate.weight q5_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  132:             blk.14.ffn_up.weight q5_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  133:           blk.14.ffn_down.weight q5_K     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  134:          blk.14.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  135:           blk.14.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  136:             blk.15.attn_q.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  137:             blk.15.attn_k.weight q5_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  138:             blk.15.attn_v.weight q6_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  139:        blk.15.attn_output.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  140:           blk.15.ffn_gate.weight q5_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  141:             blk.15.ffn_up.weight q5_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  142:           blk.15.ffn_down.weight q6_K     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  143:          blk.15.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  144:           blk.15.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  145:             blk.16.attn_q.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  146:             blk.16.attn_k.weight q5_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  147:             blk.16.attn_v.weight q5_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  148:        blk.16.attn_output.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  149:           blk.16.ffn_gate.weight q5_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  150:             blk.16.ffn_up.weight q5_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  151:           blk.16.ffn_down.weight q5_K     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  152:          blk.16.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  153:           blk.16.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  154:             blk.17.attn_q.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  155:             blk.17.attn_k.weight q5_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  156:             blk.17.attn_v.weight q5_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  157:        blk.17.attn_output.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  158:           blk.17.ffn_gate.weight q5_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  159:             blk.17.ffn_up.weight q5_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  160:           blk.17.ffn_down.weight q5_K     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  161:          blk.17.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  162:           blk.17.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  163:             blk.18.attn_q.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  164:             blk.18.attn_k.weight q5_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  165:             blk.18.attn_v.weight q6_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  166:        blk.18.attn_output.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  167:           blk.18.ffn_gate.weight q5_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  168:             blk.18.ffn_up.weight q5_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  169:           blk.18.ffn_down.weight q6_K     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  170:          blk.18.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  171:           blk.18.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  172:             blk.19.attn_q.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  173:             blk.19.attn_k.weight q5_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  174:             blk.19.attn_v.weight q5_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  175:        blk.19.attn_output.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  176:           blk.19.ffn_gate.weight q5_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  177:             blk.19.ffn_up.weight q5_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  178:           blk.19.ffn_down.weight q5_K     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  179:          blk.19.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  180:           blk.19.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  181:             blk.20.attn_q.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  182:             blk.20.attn_k.weight q5_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  183:             blk.20.attn_v.weight q5_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  184:        blk.20.attn_output.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  185:           blk.20.ffn_gate.weight q5_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  186:             blk.20.ffn_up.weight q5_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  187:           blk.20.ffn_down.weight q5_K     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  188:          blk.20.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  189:           blk.20.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  190:             blk.21.attn_q.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  191:             blk.21.attn_k.weight q5_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  192:             blk.21.attn_v.weight q6_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  193:        blk.21.attn_output.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  194:           blk.21.ffn_gate.weight q5_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  195:             blk.21.ffn_up.weight q5_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  196:           blk.21.ffn_down.weight q6_K     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  197:          blk.21.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  198:           blk.21.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  199:             blk.22.attn_q.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  200:             blk.22.attn_k.weight q5_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  201:             blk.22.attn_v.weight q5_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  202:        blk.22.attn_output.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  203:           blk.22.ffn_gate.weight q5_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  204:             blk.22.ffn_up.weight q5_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  205:           blk.22.ffn_down.weight q5_K     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  206:          blk.22.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  207:           blk.22.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  208:             blk.23.attn_q.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  209:             blk.23.attn_k.weight q5_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  210:             blk.23.attn_v.weight q5_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  211:        blk.23.attn_output.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  212:           blk.23.ffn_gate.weight q5_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  213:             blk.23.ffn_up.weight q5_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  214:           blk.23.ffn_down.weight q5_K     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  215:          blk.23.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  216:           blk.23.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  217:             blk.24.attn_q.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  218:             blk.24.attn_k.weight q5_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  219:             blk.24.attn_v.weight q6_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  220:        blk.24.attn_output.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  221:           blk.24.ffn_gate.weight q5_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  222:             blk.24.ffn_up.weight q5_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  223:           blk.24.ffn_down.weight q6_K     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  224:          blk.24.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  225:           blk.24.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  226:             blk.25.attn_q.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  227:             blk.25.attn_k.weight q5_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  228:             blk.25.attn_v.weight q5_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  229:        blk.25.attn_output.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  230:           blk.25.ffn_gate.weight q5_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  231:             blk.25.ffn_up.weight q5_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  232:           blk.25.ffn_down.weight q5_K     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  233:          blk.25.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  234:           blk.25.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  235:             blk.26.attn_q.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  236:             blk.26.attn_k.weight q5_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  237:             blk.26.attn_v.weight q5_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  238:        blk.26.attn_output.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  239:           blk.26.ffn_gate.weight q5_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  240:             blk.26.ffn_up.weight q5_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  241:           blk.26.ffn_down.weight q5_K     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  242:          blk.26.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  243:           blk.26.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  244:             blk.27.attn_q.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  245:             blk.27.attn_k.weight q5_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  246:             blk.27.attn_v.weight q6_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  247:        blk.27.attn_output.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  248:           blk.27.ffn_gate.weight q5_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  249:             blk.27.ffn_up.weight q5_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  250:           blk.27.ffn_down.weight q6_K     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  251:          blk.27.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  252:           blk.27.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  253:             blk.28.attn_q.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  254:             blk.28.attn_k.weight q5_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  255:             blk.28.attn_v.weight q6_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  256:        blk.28.attn_output.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  257:           blk.28.ffn_gate.weight q5_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  258:             blk.28.ffn_up.weight q5_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  259:           blk.28.ffn_down.weight q6_K     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  260:          blk.28.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  261:           blk.28.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  262:             blk.29.attn_q.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  263:             blk.29.attn_k.weight q5_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  264:             blk.29.attn_v.weight q6_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  265:        blk.29.attn_output.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  266:           blk.29.ffn_gate.weight q5_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  267:             blk.29.ffn_up.weight q5_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  268:           blk.29.ffn_down.weight q6_K     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  269:          blk.29.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  270:           blk.29.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  271:             blk.30.attn_q.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  272:             blk.30.attn_k.weight q5_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  273:             blk.30.attn_v.weight q6_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  274:        blk.30.attn_output.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  275:           blk.30.ffn_gate.weight q5_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  276:             blk.30.ffn_up.weight q5_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  277:           blk.30.ffn_down.weight q6_K     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  278:          blk.30.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  279:           blk.30.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  280:             blk.31.attn_q.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  281:             blk.31.attn_k.weight q5_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  282:             blk.31.attn_v.weight q6_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  283:        blk.31.attn_output.weight q5_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  284:           blk.31.ffn_gate.weight q5_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  285:             blk.31.ffn_up.weight q5_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  286:           blk.31.ffn_down.weight q6_K     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  287:          blk.31.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  288:           blk.31.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  289:               output_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  290:                    output.weight q6_K     [  4096, 32002,     1,     1 ]\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.name str              = open-orca_mistral-7b-openorca\n",
      "llama_model_loader: - kv   2:                       llama.context_length u32              = 32768\n",
      "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 4096\n",
      "llama_model_loader: - kv   4:                          llama.block_count u32              = 32\n",
      "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 14336\n",
      "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 32\n",
      "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 8\n",
      "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 10000.000000\n",
      "llama_model_loader: - kv  11:                          general.file_type u32              = 17\n",
      "llama_model_loader: - kv  12:                       tokenizer.ggml.model str              = llama\n",
      "llama_model_loader: - kv  13:                      tokenizer.ggml.tokens arr[str,32002]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
      "llama_model_loader: - kv  14:                      tokenizer.ggml.scores arr[f32,32002]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
      "llama_model_loader: - kv  15:                  tokenizer.ggml.token_type arr[i32,32002]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
      "llama_model_loader: - kv  16:                tokenizer.ggml.bos_token_id u32              = 1\n",
      "llama_model_loader: - kv  17:                tokenizer.ggml.eos_token_id u32              = 32000\n",
      "llama_model_loader: - kv  18:            tokenizer.ggml.unknown_token_id u32              = 0\n",
      "llama_model_loader: - kv  19:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:   65 tensors\n",
      "llama_model_loader: - type q5_K:  193 tensors\n",
      "llama_model_loader: - type q6_K:   33 tensors\n",
      "llm_load_vocab: special tokens definition check successful ( 261/32002 ).\n",
      "llm_load_print_meta: format           = GGUF V2\n",
      "llm_load_print_meta: arch             = llama\n",
      "llm_load_print_meta: vocab type       = SPM\n",
      "llm_load_print_meta: n_vocab          = 32002\n",
      "llm_load_print_meta: n_merges         = 0\n",
      "llm_load_print_meta: n_ctx_train      = 32768\n",
      "llm_load_print_meta: n_embd           = 4096\n",
      "llm_load_print_meta: n_head           = 32\n",
      "llm_load_print_meta: n_head_kv        = 8\n",
      "llm_load_print_meta: n_layer          = 32\n",
      "llm_load_print_meta: n_rot            = 128\n",
      "llm_load_print_meta: n_gqa            = 4\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 14336\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 10000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_yarn_orig_ctx  = 32768\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: model type       = 7B\n",
      "llm_load_print_meta: model ftype      = mostly Q5_K - Medium\n",
      "llm_load_print_meta: model params     = 7.24 B\n",
      "llm_load_print_meta: model size       = 4.78 GiB (5.67 BPW) \n",
      "llm_load_print_meta: general.name   = open-orca_mistral-7b-openorca\n",
      "llm_load_print_meta: BOS token = 1 '<s>'\n",
      "llm_load_print_meta: EOS token = 32000 '<dummy32000>'\n",
      "llm_load_print_meta: UNK token = 0 '<unk>'\n",
      "llm_load_print_meta: LF token  = 13 '<0x0A>'\n",
      "llm_load_tensors: ggml ctx size =    0.11 MiB\n",
      "llm_load_tensors: using CUDA for GPU acceleration\n",
      "llm_load_tensors: mem required  = 4742.11 MiB\n",
      "llm_load_tensors: offloading 1 repeating layers to GPU\n",
      "llm_load_tensors: offloaded 1/35 layers to GPU\n",
      "llm_load_tensors: VRAM used: 151.00 MiB\n",
      "..................................................................................................\n",
      "llama_new_context_with_model: n_ctx      = 3900\n",
      "llama_new_context_with_model: freq_base  = 10000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n",
      "llama_new_context_with_model: kv self size  =  487.50 MiB\n",
      "llama_build_graph: non-view tensors processed: 740/740\n",
      "llama_new_context_with_model: compute buffer total size = 278.43 MiB\n",
      "llama_new_context_with_model: VRAM scratch buffer: 275.37 MiB\n",
      "llama_new_context_with_model: total VRAM used: 426.37 MiB (model: 151.00 MiB, context: 275.37 MiB)\n",
      "AVX = 1 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | \n"
     ]
    }
   ],
   "source": [
    "llm = LlamaCPP(\n",
    "    # You can pass in the URL to a GGML model to download it automatically\n",
    "    #model_url=model_url,\n",
    "    # optionally, you can set the path to a pre-downloaded model instead of model_url\n",
    "    model_path=mpath,\n",
    "    temperature=0.1,\n",
    "    max_new_tokens=256,\n",
    "    # llama2 has a context window of 4096 tokens, but we set it lower to allow for some wiggle room\n",
    "    context_window=3900,\n",
    "    # kwargs to pass to __call__()\n",
    "    generate_kwargs={},\n",
    "    # kwargs to pass to __init__()\n",
    "    # set to at least 1 to use GPU\n",
    "    model_kwargs={\"n_gpu_layers\": 1},\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a37804f-6c31-45e1-9b9f-657887d3c423",
   "metadata": {},
   "source": [
    "!pip install llama-index chromadb --quiet\n",
    "!pip install chromadb\n",
    "!pip install sentence-transformers\n",
    "!pip install pydantic==1.10.11"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf19f26e",
   "metadata": {},
   "source": [
    "https://docs.llamaindex.ai/en/stable/examples/low_level/oss_ingestion_retrieval.html\n",
    "\n",
    "https://docs.llamaindex.ai/en/latest/examples/vector_stores/ChromaIndexDemo.html\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7b77fa-361b-4750-a7f9-11b2917d867a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d20d0419-e18e-4526-a831-278b5621c176",
   "metadata": {},
   "source": [
    "!mkdir -p 'data/paul_graham/'\n",
    "!wget 'https://raw.githubusercontent.com/run-llama/llama_index/main/docs/examples/data/paul_graham/paul_graham_essay.txt' -O 'data/paul_graham/paul_graham_essay.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b73dbf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "from llama_index import VectorStoreIndex, SimpleDirectoryReader, ServiceContext\n",
    "from llama_index.vector_stores import ChromaVectorStore\n",
    "from llama_index.storage.storage_context import StorageContext\n",
    "from llama_index.embeddings import HuggingFaceEmbedding\n",
    "from IPython.display import Markdown, display\n",
    "import chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58fb87ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-small-en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c5ccbca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sankar/anaconda3/envs/llamacpp/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "config.json: 100%|██████████| 777/777 [00:00<00:00, 1.56MB/s]\n",
      "model.safetensors: 100%|██████████| 438M/438M [02:05<00:00, 3.50MB/s] \n",
      "tokenizer_config.json: 100%|██████████| 366/366 [00:00<00:00, 811kB/s]\n",
      "vocab.txt: 100%|██████████| 232k/232k [00:00<00:00, 4.39MB/s]\n",
      "tokenizer.json: 100%|██████████| 711k/711k [00:00<00:00, 13.1MB/s]\n",
      "special_tokens_map.json: 100%|██████████| 125/125 [00:00<00:00, 231kB/s]\n"
     ]
    }
   ],
   "source": [
    "# create client and a new collection\n",
    "#chroma_client = chromadb.EphemeralClient()\n",
    "chroma_client = chromadb.Client()\n",
    "chroma_collection = chroma_client.create_collection(\"quickstart\")\n",
    "\n",
    "# define embedding function\n",
    "embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-base-en-v1.5\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5474a5cf-c472-4aa0-bf82-57ee4b5f694e",
   "metadata": {},
   "source": [
    "# load documents\n",
    "documents = SimpleDirectoryReader(\"./data/paul_graham/\").load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3af5ff0d-aecc-4e78-bebd-7727a26844f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = YoutubeTranscriptReader()\n",
    "documents = loader.load_data(ytlinks=['https://www.youtube.com/watch?v=xS4dkhBGh1Y&list=PL6ZR-sD5vIlw3o7IBFfLsvC6Hw72h-LLK&index=2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eee1802-ea7f-4fb1-967c-1b0ecf56f4e8",
   "metadata": {},
   "source": [
    "documents = YoutubeTranscriptReader(\"https://www.youtube.com/watch?v=xS4dkhBGh1Y&list=PL6ZR-sD5vIlw3o7IBFfLsvC6Hw72h-LLK&index=2\").load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "107c178b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up ChromaVectorStore and load in data\n",
    "vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "service_context = ServiceContext.from_defaults(llm=llm,embed_model=embed_model)\n",
    "index1 = VectorStoreIndex.from_documents(\n",
    "    documents, storage_context=storage_context, service_context=service_context\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "08ca94c5-07bb-4356-988e-e7a1c1a941a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2547.08 ms\n",
      "llama_print_timings:      sample time =      40.16 ms /   110 runs   (    0.37 ms per token,  2738.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =   15399.18 ms /  2300 tokens (    6.70 ms per token,   149.36 tokens per second)\n",
      "llama_print_timings:        eval time =   19044.51 ms /   109 runs   (  174.72 ms per token,     5.72 tokens per second)\n",
      "llama_print_timings:       total time =   34712.42 ms\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<b>\n",
       "The East India Company's initial focus on spices led them into competition with the Dutch, who had superior ships and financial resources. By 1630, the English lost this competition, leading to a shift in focus from spices to textiles. The English began trading cotton from Gujarat, which was considered a luxury item at the time. This trade eventually led to the development of the textile industry in England, and the eventual decline of the East India Company's monopoly on spice trade.</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Query Data\n",
    "query_engine1 = index1.as_query_engine()\n",
    "response = query_engine1.query(\"please summarize in 200 words or less?\")\n",
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18034659-1b82-4c65-99a0-857ce2cd1690",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "55fe8971-97d5-4cb6-96e2-9bb86b804a30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2547.08 ms\n",
      "llama_print_timings:      sample time =      67.35 ms /   180 runs   (    0.37 ms per token,  2672.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1213.62 ms /    12 tokens (  101.13 ms per token,     9.89 tokens per second)\n",
      "llama_print_timings:        eval time =   31390.12 ms /   179 runs   (  175.36 ms per token,     5.70 tokens per second)\n",
      "llama_print_timings:       total time =   33020.94 ms\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<b>\n",
       "The story begins with Sir James Lancaster who is not a very successful sea captain. He loses his flotilla and many of his crew to cannibals on a previous voyage. However, he manages to bump into a Portuguese ship which he takes everything from and goes home. This marks the beginning of a tricky 30 years for the British as they compete against the Dutch in the spice trade. The Dutch, being a new nation with better ships and sea captains, eventually win and the English are left with a muddy island called Manhattan.\n",
       "\n",
       "Realizing that the days of the spice trade have passed, the English shift their focus to textiles. They start importing cotton from Bengal, which was considered a luxury item in ancient times. The British begin wearing cotton instead of wool, which is unsuitable for the tropics.</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Query Data\n",
    "query_engine1 = index1.as_query_engine()\n",
    "response = query_engine1.query(\"please summarize in 500 words or less?\")\n",
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f1cb940e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2547.08 ms\n",
      "llama_print_timings:      sample time =      21.78 ms /    61 runs   (    0.36 ms per token,  2800.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =   14979.63 ms /  2278 tokens (    6.58 ms per token,   152.07 tokens per second)\n",
      "llama_print_timings:        eval time =   10311.30 ms /    60 runs   (  171.86 ms per token,     5.82 tokens per second)\n",
      "llama_print_timings:       total time =   25431.53 ms\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<b>1) The person who is speaking in this episode is not explicitly named but they discuss the history of the East India Company and its founder, customer Smythe. 2) Another speaker mentioned in the context is historian William, who provides information about the company's early days and its founder.</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Query Data\n",
    "query_engine1 = index1.as_query_engine()\n",
    "response = query_engine1.query(\"Who are the two people speaking in this episode?\")\n",
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8e76d1e2-94f2-468b-a62a-0742a9f3bdc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2547.08 ms\n",
      "llama_print_timings:      sample time =      12.67 ms /    34 runs   (    0.37 ms per token,  2683.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =   15192.13 ms /  2285 tokens (    6.65 ms per token,   150.41 tokens per second)\n",
      "llama_print_timings:        eval time =    5616.89 ms /    33 runs   (  170.21 ms per token,     5.88 tokens per second)\n",
      "llama_print_timings:       total time =   20890.29 ms\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<b> This episode discusses the history of Indian artifacts and treasures that were looted during British colonization and are now housed in a private collection in Wales.</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = query_engine1.query(\"Ine one sentence what is this epidose about?\")\n",
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "cd44d588-28af-44a4-9d3f-e8991e340237",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2547.08 ms\n",
      "llama_print_timings:      sample time =      60.72 ms /   164 runs   (    0.37 ms per token,  2701.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =   15495.84 ms /  2344 tokens (    6.61 ms per token,   151.27 tokens per second)\n",
      "llama_print_timings:        eval time =   28330.51 ms /   163 runs   (  173.81 ms per token,     5.75 tokens per second)\n",
      "llama_print_timings:       total time =   44208.21 ms\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<b>\n",
       "In this podcast, William and Anita delve into the fascinating history of The East India Company, which began as a small corporation in Tudor England. They discuss how this company, founded by auditor-turned-entrepreneur Sir George Auditor Smith, managed to grow rapidly and eventually conquer vast territories in India. Despite being outnumbered and having fewer resources compared to their opponents, the English adventurers were able to subdue North India through a series of strategic battles. The podcast also touches upon the role of privateers, who were licensed by the state to loot treasure ships, in helping the East India Company establish its presence in the region. Overall, this engaging discussion provides listeners with an insightful look into the rise and influence of The East India Company in India.</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = query_engine1.query(\"The blurb for this podcasts says the following.In the opening episode, William and Anita discuss the rise of The East India Company, exploring how a small corporation founded in Tudor England - with only a handful of employees - came to rule India. With that in mind, give a 5 sentence paragraph for each 5 minute of this 60 minute podcast\")\n",
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6feb4a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.node_parser.text import SentenceSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c4069635",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_parser = SentenceSplitter(\n",
    "    chunk_size=1024,\n",
    "    # separator=\" \",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "350a3c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_chunks = []\n",
    "# maintain relationship with source doc index, to help inject doc metadata in (3)\n",
    "doc_idxs = []\n",
    "for doc_idx, doc in enumerate(documents):\n",
    "    cur_text_chunks = text_parser.split_text(doc.text)\n",
    "    text_chunks.extend(cur_text_chunks)\n",
    "    doc_idxs.extend([doc_idx] * len(cur_text_chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ea7cfff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.schema import TextNode\n",
    "\n",
    "nodes = []\n",
    "for idx, text_chunk in enumerate(text_chunks):\n",
    "    node = TextNode(\n",
    "        text=text_chunk,\n",
    "    )\n",
    "    src_doc = documents[doc_idxs[idx]]\n",
    "    node.metadata = src_doc.metadata\n",
    "    nodes.append(node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "84934faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for node in nodes:\n",
    "    node_embedding = embed_model.get_text_embedding(\n",
    "        node.get_content(metadata_mode=\"all\")\n",
    "    )\n",
    "    node.embedding = node_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4723de9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['7b5044b1-2cd6-44b1-aa18-3d01ea24eada',\n",
       " 'c6ce0ee4-af53-4f17-95d4-546d2e010f7f',\n",
       " '712e2d31-9bf1-4b4e-8279-9c54544f8f8a',\n",
       " 'f9e2ee83-eec3-4373-a91b-827d092d6216',\n",
       " '5a42490d-3559-4725-ae37-9a78a3d0a970',\n",
       " 'bc386350-9c75-4750-916c-9bf07c18e808',\n",
       " '2cf7bb84-0bab-4d5f-b8af-29f43bce9859',\n",
       " '16b54ef7-4875-4430-93d5-50111066349c',\n",
       " '134bc013-f0a7-4476-84ab-3d55fe1922d5',\n",
       " 'f0fd968d-4140-4d1d-9da0-ea5d3ce8f08c',\n",
       " 'd3c182a0-0744-429a-8478-8a0cff94e85c',\n",
       " 'de0159bd-a164-4428-9359-beb7b922cbb5',\n",
       " '47953010-b812-41bd-9321-0c42cd2dedb9',\n",
       " '5e0346e5-b733-42fe-9281-c6b4f8e7aa8c',\n",
       " 'dc7aa922-07b6-45c5-bcda-b4d315010e49',\n",
       " '5147d09c-7a11-4fdc-a7f2-71c18fa6d9fb',\n",
       " '3832dc89-110c-4f79-a02a-89c4e77fc2ec',\n",
       " 'f7934960-c8c0-4d8d-82e2-0745d0f7b162']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_store.add(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2c4020ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_str = \"What did Clive acheive?\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2c431e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_embedding = embed_model.get_query_embedding(query_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ab9e59d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct vector store query\n",
    "from llama_index.vector_stores import VectorStoreQuery\n",
    "\n",
    "query_mode = \"default\"\n",
    "# query_mode = \"sparse\"\n",
    "# query_mode = \"hybrid\"\n",
    "\n",
    "vector_store_query = VectorStoreQuery(\n",
    "    query_embedding=query_embedding, similarity_top_k=2, mode=query_mode\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4f4e7dec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "and\n",
      "everyone laughs and he's off there and\n",
      "there's oh oh Clive but that explains\n",
      "where we started Paris Castle stuff not\n",
      "quite not right no no no nearly so what\n",
      "happens then is that Clive gets his\n",
      "million and eight years later all the\n",
      "people that he has put into power as\n",
      "puppies again rise up against English\n",
      "because the English have behaved so\n",
      "incredibly badly and basically you know\n",
      "killed the goose that was laying the\n",
      "golden egg in just eight years they lay\n",
      "waste to Bengal by asset stripping it\n",
      "and there is another big uh Act of\n",
      "resistance and not just the nawab of\n",
      "Bengal this time who's now called me a\n",
      "customer man actually put in by by Clive\n",
      "but uh also the nawab of of avid which\n",
      "is basically uttar Pradesh who's called\n",
      "shuja odala and the Mughal Emperor\n",
      "himself\n",
      "all meet at the Battle of buxar and they\n",
      "take on uh the East India Company but\n",
      "again the company has used the money\n",
      "that it's gathered to enormously\n",
      "increase the size of its sepoyamin it's\n",
      "bought an enormous number of sepoys and\n",
      "there are now 40 000 trained up sea\n",
      "points trained in the latest European\n",
      "techniques of warfare horse artillery\n",
      "18th century ballistics muskets Bandits\n",
      "and it's a hard-fought battle but the\n",
      "east Indian company's Army defeats all\n",
      "three of these armies Mass together\n",
      "and this is the moment when the Clive\n",
      "returns to India and makes\n",
      "and suddenly you find that the richest\n",
      "provinces of India three responses\n",
      "Bengal Bihar and erisa are signed over\n",
      "not to the British government\n",
      "not to the British army but to a private\n",
      "Corporation the East India Company and\n",
      "that ladies and gentlemen is how you\n",
      "tell a story and it's not it's not even\n",
      "the end is it it's just the end of the\n",
      "beginning this is now the moment that\n",
      "the company moves from being a trading\n",
      "organization to suddenly it's an\n",
      "imperial territorial power and if you\n",
      "want to know more about that do listen\n",
      "to the next podcast that's all from me\n",
      "Anita Anand and William\n",
      "[Music]\n"
     ]
    }
   ],
   "source": [
    "# returns a VectorStoreQueryResult\n",
    "query_result = vector_store.query(vector_store_query)\n",
    "print(query_result.nodes[0].get_content())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c43e4866",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.schema import NodeWithScore\n",
    "from typing import Optional\n",
    "\n",
    "nodes_with_scores = []\n",
    "for index, node in enumerate(query_result.nodes):\n",
    "    score: Optional[float] = None\n",
    "    if query_result.similarities is not None:\n",
    "        score = query_result.similarities[index]\n",
    "    nodes_with_scores.append(NodeWithScore(node=node, score=score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "47fc0017",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import QueryBundle\n",
    "from llama_index.retrievers import BaseRetriever\n",
    "from typing import Any, List\n",
    "\n",
    "\n",
    "class VectorDBRetriever(BaseRetriever):\n",
    "    \"\"\"Retriever over a chroma vector store.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        vector_store: ChromaVectorStore,\n",
    "        embed_model: Any,\n",
    "        query_mode: str = \"default\",\n",
    "        similarity_top_k: int = 2,\n",
    "    ) -> None:\n",
    "        \"\"\"Init params.\"\"\"\n",
    "        self._vector_store = vector_store\n",
    "        self._embed_model = embed_model\n",
    "        self._query_mode = query_mode\n",
    "        self._similarity_top_k = similarity_top_k\n",
    "        super().__init__()\n",
    "\n",
    "    def _retrieve(self, query_bundle: QueryBundle) -> List[NodeWithScore]:\n",
    "        \"\"\"Retrieve.\"\"\"\n",
    "        query_embedding = embed_model.get_query_embedding(\n",
    "            query_bundle.query_str\n",
    "        )\n",
    "        vector_store_query = VectorStoreQuery(\n",
    "            query_embedding=query_embedding,\n",
    "            similarity_top_k=self._similarity_top_k,\n",
    "            mode=self._query_mode,\n",
    "        )\n",
    "        query_result = vector_store.query(vector_store_query)\n",
    "\n",
    "        nodes_with_scores = []\n",
    "        for index, node in enumerate(query_result.nodes):\n",
    "            score: Optional[float] = None\n",
    "            if query_result.similarities is not None:\n",
    "                score = query_result.similarities[index]\n",
    "            nodes_with_scores.append(NodeWithScore(node=node, score=score))\n",
    "\n",
    "        return nodes_with_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "51df581f",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = VectorDBRetriever(\n",
    "    vector_store, embed_model, query_mode=\"default\", similarity_top_k=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b00fa1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.query_engine import RetrieverQueryEngine\n",
    "\n",
    "query_engine = RetrieverQueryEngine.from_args(\n",
    "    retriever, service_context=service_context\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b34416db",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_str = \"What did Clive acheive?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d3430de6-c501-4f62-8aad-b7af1d2dfafc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nIn this podcast, William and Anita delve into the fascinating history of The East India Company, which began as a small corporation in Tudor England. They discuss how this company, founded by auditor-turned-entrepreneur Sir George Auditor Smith, managed to grow rapidly and eventually conquer vast territories in India. Despite being outnumbered and having fewer resources compared to their opponents, the English adventurers were able to subdue North India through a series of strategic battles. The podcast also touches upon the role of privateers, who were licensed by the state to loot treasure ships, in helping the East India Company establish its presence in the region. Overall, this engaging discussion provides listeners with an insightful look into the rise and influence of The East India Company in India.'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "27497029-048d-457c-9891-02bbd748c167",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2547.08 ms\n",
      "llama_print_timings:      sample time =      19.98 ms /    56 runs   (    0.36 ms per token,  2803.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6288.52 ms /  1084 tokens (    5.80 ms per token,   172.38 tokens per second)\n",
      "llama_print_timings:        eval time =    8861.53 ms /    55 runs   (  161.12 ms per token,     6.21 tokens per second)\n",
      "llama_print_timings:       total time =   15274.07 ms\n"
     ]
    }
   ],
   "source": [
    "query_str = \"What did Clive acheive?\"\n",
    "\n",
    "response = query_engine.query(query_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f8a7ba07-085d-4046-b6df-8e59915b84d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<b>\n",
       "Clive achieved significant victories in India, which led to him being awarded a million pounds. He established the East India Company as a powerful force in India. His actions set the stage for the company's transformation from a trading organization to an imperial territorial power.</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "3029bb14-2ae9-47f5-bf32-0154ddac65ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2547.08 ms\n",
      "llama_print_timings:      sample time =       2.18 ms /     6 runs   (    0.36 ms per token,  2751.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =   15197.84 ms /  2274 tokens (    6.68 ms per token,   149.63 tokens per second)\n",
      "llama_print_timings:        eval time =     838.47 ms /     5 runs   (  167.69 ms per token,     5.96 tokens per second)\n",
      "llama_print_timings:       total time =   16055.93 ms\n"
     ]
    }
   ],
   "source": [
    "query_str = \"what years is this episode covering\"\n",
    "\n",
    "response = query_engine.query(query_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "58e2c238-46b3-4f0e-96a2-8c3321c6ba87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<b>1590s</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ced8c12f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2547.08 ms\n",
      "llama_print_timings:      sample time =      50.08 ms /   140 runs   (    0.36 ms per token,  2795.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2083.06 ms /   422 tokens (    4.94 ms per token,   202.59 tokens per second)\n",
      "llama_print_timings:        eval time =   22125.79 ms /   139 runs   (  159.18 ms per token,     6.28 tokens per second)\n",
      "llama_print_timings:       total time =   24516.83 ms\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<b>\n",
       "Clive of India, also known as Robert Clive, was a prominent British military officer who played a significant role in shaping the British Empire's presence in India. Born in England, he went on to make a name for himself through his military accomplishments and strategic prowess. As a product of the British Empire, Clive's life and career were deeply intertwined with the expansionist policies of his time. His actions in India contributed to the establishment of British rule over large parts of the Indian subcontinent. Despite the complexities of his legacy, Clive of India remains an important figure in understanding the history of the British Empire and its impact on India.</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "query_str = \"Write a bruief biography of Clive of India strictly based on the facts and thoughts experessed in this podcast?\"\n",
    "\n",
    "response = query_engine.query(query_str)\n",
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "2b4cf0e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2547.08 ms\n",
      "llama_print_timings:      sample time =      92.31 ms /   252 runs   (    0.37 ms per token,  2730.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =   15096.97 ms /  2289 tokens (    6.60 ms per token,   151.62 tokens per second)\n",
      "llama_print_timings:        eval time =   43108.52 ms /   251 runs   (  171.75 ms per token,     5.82 tokens per second)\n",
      "llama_print_timings:       total time =   58791.97 ms\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<b>\n",
       "The podcast discusses the East India Company's journey to control a vast territory like India. It begins with the founder of the company, customer or auditor Smythe, who was an accountant and ran the customs of London. He had the idea that if the Dutch could get to the East Indies (Indonesia) and buy spices by cutting out all middlemen, so can the English. He appealed to the patriotism of rich investors and called in privateers or robbers who were licensed by the state to loot treasure ships.\n",
       "\n",
       "The podcast then moves on to discuss how England cut itself off from the continent after the Reformation and rivalry with Spain and Portugal. The Dutch, who were Protestants like the English, had made a fortune after their pioneering visit to the spice lands. This led to the idea that the East India Company could also subdue all opposition in North India.\n",
       "\n",
       "The podcast then circles back to the question of how a group of adventurers managed to control such a vast country as India despite being outnumbered and having less strength in arms. The answer lies in their determination, patriotism, and the support from their home country, England.</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "query_str = \"Summarize in 300 words, the last 15 minutes of the podcast. ?\"\n",
    "\n",
    "response = query_engine.query(query_str)\n",
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b744e8cb-1bd1-4fe0-9d4e-8bea9ed67cd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2547.08 ms\n",
      "llama_print_timings:      sample time =      25.13 ms /    69 runs   (    0.36 ms per token,  2746.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2075.39 ms /   408 tokens (    5.09 ms per token,   196.59 tokens per second)\n",
      "llama_print_timings:        eval time =   10742.83 ms /    68 runs   (  157.98 ms per token,     6.33 tokens per second)\n",
      "llama_print_timings:       total time =   12976.45 ms\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<b>\n",
       "From the given context, we know that Anita Anand is a person of Indian origin who was born in Essex. She identifies herself as an \"Indian in Britain\". She is one half of the podcast duo Empire along with William Durham pool. The podcast discusses the British Empire and its impact on India.</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = query_engine.query(\"what do we know about Anita Anand?\")\n",
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e332df59-4ab8-4ac4-9ced-08b3a5b0b605",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2547.08 ms\n",
      "llama_print_timings:      sample time =      37.05 ms /   102 runs   (    0.36 ms per token,  2753.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =   15028.94 ms /  2276 tokens (    6.60 ms per token,   151.44 tokens per second)\n",
      "llama_print_timings:        eval time =   17342.21 ms /   101 runs   (  171.71 ms per token,     5.82 tokens per second)\n",
      "llama_print_timings:       total time =   32605.21 ms\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<b>\n",
       "William Dalrymple is a British historian, author, and journalist who specializes in Indian history and culture. He was born in Scotland but has spent much of his life living and working in India. His writing focuses on the historical interactions between Britain and India, particularly during the colonial period. Some of his notable works include \"The Age of Kali: The Eighteenth Century in India\" and \"White Mughals: Love & Betrayal in 18th Century India.\"</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "query_str = \"What do we know about William Dalrymple\"\n",
    "\n",
    "response = query_engine.query(query_str)\n",
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "fcc0491d-e173-4609-885c-c8b3e585f071",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2547.08 ms\n",
      "llama_print_timings:      sample time =      39.49 ms /   107 runs   (    0.37 ms per token,  2709.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =   15328.45 ms /  2282 tokens (    6.72 ms per token,   148.87 tokens per second)\n",
      "llama_print_timings:        eval time =   18758.21 ms /   106 runs   (  176.96 ms per token,     5.65 tokens per second)\n",
      "llama_print_timings:       total time =   34360.42 ms\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<b>\n",
       "From the given context, it is clear that William Dalrymple is a historian who has a deep interest in the history of the East India Company and its founder, customer Smythe. He appears to be knowledgeable about the historical events surrounding the company's formation and its early ventures into the spice trade. His enthusiasm for the subject matter is evident as he discusses the fascinating story of how an English company managed to subdue a vast territory like India despite being outnumbered and having fewer resources.</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "query_str = \"What do we glean about William Dalrymple from this podcast\"\n",
    "\n",
    "response = query_engine.query(query_str)\n",
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "3bb506b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[NodeWithScore(node=TextNode(id_='4b64d2fc-0f91-475c-8855-e9de5b9f1457', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a', text=\"is\\nthe moment before that episode this is\\nthe moment when an English company first\\ngets its hands on this incredibly Rich\\nterritory and it's done it in two stages\\nfirst to be and we'll we'll deal with\\nthis over the course of the next uh uh\\nhour of this podcast but the uh the\\nfirst stage is the battle plasti the\\nsecond stage of the battle of buxar and\\nthis signing of this document takes\\nplace immediately after the Second\\nBattle okay when the East India company\\nhas now basically subdued all opposition\\nand North India we okay I think that's\\ncan we Circle back to that because I\\nstill want to know and this is a\\nquestion that Indians ask all the time\\nhow is it that in numbers we outnumbered\\nin strength of arms we were more\\npowerful together and yet\\na group of adventurers managed to subdue\\nand control a country as vast as India\\nso can we go right right right right\\nback to the first birth whales the\\nCradle whales of what would become the\\nEast India Company and this really\\nfascinating man who I just love\\nhistorian William called if we are going\\nto be called what we do customer Smythe\\ncan we start with him\\nso these Tinder company is a company a\\ncorporation and like any company it\\nstarts up as a startup effectively uh\\nand uh the guy who has the idea the\\nfounder of this company is a man called\\ncustomer or auditor Smythe\\nso-called because he was an auditor in\\nother words an accountant uh who ended\\nup running the Customs\\num and ran the customs of London so he's\\na he's the kind of Richard Branson of\\nhis day or the Vijay Malia of his day\\nhe's an entrepreneurs made a lot of\\nmoney his dad was a big entrepreneur\\nbefore him he's inherited the money but\\nhe's hugely enlarged that\\nand so when the news comes in the late\\n1590s during now this is the year that\\num Elizabeth actually is about 80 years\\nold an old woman now everyone's slightly\\nwondering what's going to happen when\\nshe dies\\nuh this is also the uh incident need\\nthat Shakespeare is writing both Hamlet\\nand Julius Caesar which I saw last night\\nin the globe and if you had walked from\\nthe globe in 1599\\nover sutherbridge\\ninto what was then moorgate Fields not a\\ngrotty tube station in those days but uh\\nFields as the name suggests and in the\\nmiddle is a is a gorgeous black and\\nwhite Tudor building called the Founders\\nHall The customersmith Hires that for\\nthe day\\nand he calls all the rich investors the\\nthe people who you think can invest in\\nin his Venture and he says the Dutch had\\njust gone to the East Indies by the East\\nIndies he means what we now call\\nIndonesia not India in Italy right and\\nthe this the early days of the company's\\naimed not at all at India interestingly\\nbut at Indonesia and even Beyond The\\nSpice Islands on the edge of Papua New\\nGuinea\\nand he has the idea that if the Dutch\\ncan get there and buy spaces cutting out\\nall the middlemen cutting out the Arabs\\ncutting out the venetians cutting out\\nthe north Europeans\\nso can the English and so he he's he\\nappeals to their Tudor patriotism and he\\ncalls in a lot of people that we today\\nwere called Pirates because privateers\\nright okay the privateers the people who\\nhave been licensed by the state to loot\\nthe treasure ships uh moving Gold Silver\\nand other precious objects from South\\nAmerica to put Spain and Portugal again\\nI mean you you're so familiar but to\\nsomeone to somebody who is not that is\\nan astonishing thing that the state is\\ngiving full power to robbers ostensibly\\nto go and Rob well it's a it's actually\\nquite a familiar situation because in\\nthe immediate run-up to this England\\njust cut itself off from the continent\\nand in in this case uh uh not the uh not\\nthe of course the European Community\\nwhich hasn't been founded yet but the\\nReformation has cut it off from the\\nwhole of southern Europe and and\\ncountries like Spain and Portugal regard\\nuh England as a dangerous enemy State\\nand there's an awful lot of rivalry uh\\nthis is just after the Spanish Armada\\nthis is uh Philip II is just dead uh and\\nuh there's an awful lot of uh of dislike\\nof uh of Catholic Spain and and the and\\nthe popeish continent as they said but\\neven the Protestants are not necessarily\\nvery friendly towards the English and\\nthe Dutch who are Protestant who have\\njust broken free from Spain have made\\nthis pioneering visit to the spicelands\\nand made a fortune and the reason that\\nthe Dutch again the\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.4168186640707654),\n",
       " NodeWithScore(node=TextNode(id_='bc386350-9c75-4750-916c-9bf07c18e808', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a', text=\"is\\nthe moment before that episode this is\\nthe moment when an English company first\\ngets its hands on this incredibly Rich\\nterritory and it's done it in two stages\\nfirst to be and we'll we'll deal with\\nthis over the course of the next uh uh\\nhour of this podcast but the uh the\\nfirst stage is the battle plasti the\\nsecond stage of the battle of buxar and\\nthis signing of this document takes\\nplace immediately after the Second\\nBattle okay when the East India company\\nhas now basically subdued all opposition\\nand North India we okay I think that's\\ncan we Circle back to that because I\\nstill want to know and this is a\\nquestion that Indians ask all the time\\nhow is it that in numbers we outnumbered\\nin strength of arms we were more\\npowerful together and yet\\na group of adventurers managed to subdue\\nand control a country as vast as India\\nso can we go right right right right\\nback to the first birth whales the\\nCradle whales of what would become the\\nEast India Company and this really\\nfascinating man who I just love\\nhistorian William called if we are going\\nto be called what we do customer Smythe\\ncan we start with him\\nso these Tinder company is a company a\\ncorporation and like any company it\\nstarts up as a startup effectively uh\\nand uh the guy who has the idea the\\nfounder of this company is a man called\\ncustomer or auditor Smythe\\nso-called because he was an auditor in\\nother words an accountant uh who ended\\nup running the Customs\\num and ran the customs of London so he's\\na he's the kind of Richard Branson of\\nhis day or the Vijay Malia of his day\\nhe's an entrepreneurs made a lot of\\nmoney his dad was a big entrepreneur\\nbefore him he's inherited the money but\\nhe's hugely enlarged that\\nand so when the news comes in the late\\n1590s during now this is the year that\\num Elizabeth actually is about 80 years\\nold an old woman now everyone's slightly\\nwondering what's going to happen when\\nshe dies\\nuh this is also the uh incident need\\nthat Shakespeare is writing both Hamlet\\nand Julius Caesar which I saw last night\\nin the globe and if you had walked from\\nthe globe in 1599\\nover sutherbridge\\ninto what was then moorgate Fields not a\\ngrotty tube station in those days but uh\\nFields as the name suggests and in the\\nmiddle is a is a gorgeous black and\\nwhite Tudor building called the Founders\\nHall The customersmith Hires that for\\nthe day\\nand he calls all the rich investors the\\nthe people who you think can invest in\\nin his Venture and he says the Dutch had\\njust gone to the East Indies by the East\\nIndies he means what we now call\\nIndonesia not India in Italy right and\\nthe this the early days of the company's\\naimed not at all at India interestingly\\nbut at Indonesia and even Beyond The\\nSpice Islands on the edge of Papua New\\nGuinea\\nand he has the idea that if the Dutch\\ncan get there and buy spaces cutting out\\nall the middlemen cutting out the Arabs\\ncutting out the venetians cutting out\\nthe north Europeans\\nso can the English and so he he's he\\nappeals to their Tudor patriotism and he\\ncalls in a lot of people that we today\\nwere called Pirates because privateers\\nright okay the privateers the people who\\nhave been licensed by the state to loot\\nthe treasure ships uh moving Gold Silver\\nand other precious objects from South\\nAmerica to put Spain and Portugal again\\nI mean you you're so familiar but to\\nsomeone to somebody who is not that is\\nan astonishing thing that the state is\\ngiving full power to robbers ostensibly\\nto go and Rob well it's a it's actually\\nquite a familiar situation because in\\nthe immediate run-up to this England\\njust cut itself off from the continent\\nand in in this case uh uh not the uh not\\nthe of course the European Community\\nwhich hasn't been founded yet but the\\nReformation has cut it off from the\\nwhole of southern Europe and and\\ncountries like Spain and Portugal regard\\nuh England as a dangerous enemy State\\nand there's an awful lot of rivalry uh\\nthis is just after the Spanish Armada\\nthis is uh Philip II is just dead uh and\\nuh there's an awful lot of uh of dislike\\nof uh of Catholic Spain and and the and\\nthe popeish continent as they said but\\neven the Protestants are not necessarily\\nvery friendly towards the English and\\nthe Dutch who are Protestant who have\\njust broken free from Spain have made\\nthis pioneering visit to the spicelands\\nand made a fortune and the reason that\\nthe Dutch again the\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.4168186640707654)]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.retrieve(query_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "6f95ef2f-3c39-4e7a-a575-785a7467c3f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2547.08 ms\n",
      "llama_print_timings:      sample time =      13.63 ms /    37 runs   (    0.37 ms per token,  2714.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1703.83 ms /    15 tokens (  113.59 ms per token,     8.80 tokens per second)\n",
      "llama_print_timings:        eval time =    6331.54 ms /    36 runs   (  175.88 ms per token,     5.69 tokens per second)\n",
      "llama_print_timings:       total time =    8132.60 ms\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<b>1) The person who is speaking most of the time seems to be an historian named William. 2) The other speaker is presumably the host or interviewer of the podcast.</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = query_engine1.query(\"Who are the two people speaking in this episode?\")\n",
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "7b9dc9d3-d5a3-418e-a8fd-22b45050229b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2547.08 ms\n",
      "llama_print_timings:      sample time =      46.63 ms /   128 runs   (    0.36 ms per token,  2745.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1884.43 ms /    20 tokens (   94.22 ms per token,    10.61 tokens per second)\n",
      "llama_print_timings:        eval time =   21755.63 ms /   127 runs   (  171.30 ms per token,     5.84 tokens per second)\n",
      "llama_print_timings:       total time =   23939.37 ms\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<b>\n",
       "The podcast discusses the history of the East India Company, which was founded by Sir Auditor Smith in the late 1590s. The company initially aimed to establish a presence in Indonesia and beyond, rather than India. Sir Auditor Smith appealed to the patriotism of wealthy investors, many of whom were privateers or pirates, to fund his venture. This was during a time when England had cut itself off from the continent due to the Reformation and tensions with Catholic Spain and Portugal. The Dutch, who were also Protestant, had recently made a fortune by visiting the spice lands.</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = query_engine1.query(\"Summarise the last 15 minutes of the poidcast?\")\n",
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "f41e7efc-3338-489e-a17a-3255cff3990d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2547.08 ms\n",
      "llama_print_timings:      sample time =      40.63 ms /   110 runs   (    0.37 ms per token,  2707.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1368.74 ms /    15 tokens (   91.25 ms per token,    10.96 tokens per second)\n",
      "llama_print_timings:        eval time =   18928.65 ms /   109 runs   (  173.66 ms per token,     5.76 tokens per second)\n",
      "llama_print_timings:       total time =   20554.78 ms\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<b>1) The person who is speaking in this podcast is not explicitly named but he seems to be a historian or an expert on the topic of the East India Company. He provides detailed historical information about the company's founding, its initial focus on Indonesia and the Spice Islands, and its eventual expansion into India. 2) The other person who is speaking in this podcast is presumably the host or interviewer, who engages with the historian and asks questions to elicit more information and context about the East India Company's history.</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = query_engine.query(\"Who are the two people speaking in this episode?\")\n",
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "f5776ed0-80c0-4260-9de6-9a8d73690295",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2547.08 ms\n",
      "llama_print_timings:      sample time =      12.86 ms /    36 runs   (    0.36 ms per token,  2799.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     909.09 ms /    47 tokens (   19.34 ms per token,    51.70 tokens per second)\n",
      "llama_print_timings:        eval time =    6180.90 ms /    35 runs   (  176.60 ms per token,     5.66 tokens per second)\n",
      "llama_print_timings:       total time =    7182.30 ms\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<b>\n",
       "The podcast does not provide any information about the hosts in the initial 5 minutes or so. The context provided does not mention any details about the hosts of the podcast.</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = query_engine1.query(\"The podcast is an hour long.In th einitial 5 minutes or so the hosts introduce themselves. Can you name thema dn give detauils about them from the first 10 minutes only\")\n",
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "cadae694-054a-44fe-9aa3-1cd133ea197a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2547.08 ms\n",
      "llama_print_timings:      sample time =      88.58 ms /   256 runs   (    0.35 ms per token,  2889.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1981.49 ms /    21 tokens (   94.36 ms per token,    10.60 tokens per second)\n",
      "llama_print_timings:        eval time =   44776.48 ms /   255 runs   (  175.59 ms per token,     5.69 tokens per second)\n",
      "llama_print_timings:       total time =   47380.91 ms\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<b>\n",
       "The transcript for the first five minutes of the podcast is as follows:\n",
       "\n",
       "[Introduction]\n",
       "\n",
       "Speaker 1: Welcome to the podcast where we explore the fascinating history of India and its interactions with the world. Today, we're going to talk about the East India Company and how it came to control a vast territory in India. So let's start at the very beginning.\n",
       "\n",
       "[Start of the podcast]\n",
       "\n",
       "Speaker 1: The moment before that episode this is the moment when an English company first gets its hands on this incredibly Rich territory and it's done it in two stages first to be and we'll we'll deal with this over the course of the next uh uh hour of this podcast but the uh the first stage is the battle plasti the second stage of the battle of buxar and this signing of this document takes place immediately after the Second Battle okay when the East India company has now basically subdued all opposition and North India we okay I think that's can we Circle back to that because I still want to know and this is a question that Indians ask all the time how is it that in numbers we outnumbered in strength of arms we were more powerful</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = query_engine1.query(\"can you reproduce the transcripts of the first 5 minutes of the podcast\")\n",
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "885a98e2-427b-425c-8dca-adc0c5dbea3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2547.08 ms\n",
      "llama_print_timings:      sample time =      87.53 ms /   256 runs   (    0.34 ms per token,  2924.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   44314.49 ms /   256 runs   (  173.10 ms per token,     5.78 tokens per second)\n",
      "llama_print_timings:       total time =   44931.41 ms\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<b>\n",
       "The transcripts for the first five minutes of the podcast are as follows:\n",
       "\n",
       "\"Context information is below.\n",
       "---------------------\n",
       "is\n",
       "the moment before that episode this is\n",
       "the moment when an English company first\n",
       "gets its hands on this incredibly Rich\n",
       "territory and it's done it in two stages\n",
       "first to be and we'll we'll deal with\n",
       "this over the course of the next uh uh\n",
       "hour of this podcast but the uh the\n",
       "first stage is the battle plasti the\n",
       "second stage of the battle of buxar and\n",
       "this signing of this document takes\n",
       "place immediately after the Second\n",
       "Battle okay when the East India company\n",
       "has now basically subdued all opposition\n",
       "and North India we okay I think that's\n",
       "can we Circle back to that because I\n",
       "still want to know and this is a\n",
       "question that Indians ask all the time\n",
       "how is it that in numbers we outnumbered\n",
       "in strength of arms we were more\n",
       "powerful together and yet\n",
       "a group of adventurers managed to subdue\n",
       "and control a country as vast as India\n",
       "so can we go right right right right\n",
       "back to the first birth whales the\n",
       "Crad</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = query_engine.query(\"can you reproduce the transcripts of the first 5 minutes of the podcast\")\n",
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "be48361c-777f-4218-8109-b175f34522e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2547.08 ms\n",
      "llama_print_timings:      sample time =      87.84 ms /   256 runs   (    0.34 ms per token,  2914.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2315.26 ms /    25 tokens (   92.61 ms per token,    10.80 tokens per second)\n",
      "llama_print_timings:        eval time =   43853.69 ms /   255 runs   (  171.98 ms per token,     5.81 tokens per second)\n",
      "llama_print_timings:       total time =   46767.48 ms\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<b>\n",
       "Yes, here is the transcript for the first 30 seconds of the podcast:\n",
       "\n",
       "\"Is the moment before that episode this is the moment when an English company first gets its hands on this incredibly Rich territory and it's done it in two stages first to be and we'll we'll deal with this over the course of the next uh uh hour of this podcast but the uh the first stage is the battle plasti the second stage of the battle of buxar and this signing of this document takes place immediately after the Second Battle okay when the East India company has now basically subdued all opposition and North India we okay I think that's can we Circle back to that because I still want to know and this is a question that Indians ask all the time how is it that in numbers we outnumbered in strength of arms we were more powerful together and yet a group of adventurers managed to subdue and control a country as vast as India so can we go right right right right back to the first birth whales the Cradle whales of what would become the East India Company and this really fascinating man who I just love historian William called if we are going to be called what we do customer Smy</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = query_engine1.query(\"acn you reproduce th etranscript for the first 30 seconds of the podcast?\")\n",
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "03dadc5b-1b22-4026-ab3c-15e5c90a5cc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2547.08 ms\n",
      "llama_print_timings:      sample time =      88.36 ms /   256 runs   (    0.35 ms per token,  2897.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =   44290.74 ms /   256 runs   (  173.01 ms per token,     5.78 tokens per second)\n",
      "llama_print_timings:       total time =   44901.73 ms\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<b>\n",
       "The transcript for the first 30 seconds of the podcast is as follows:\n",
       "\"Is the moment before that episode this is the moment when an English company first gets its hands on this incredibly Rich territory and it's done it in two stages first to be and we'll we'll deal with this over the course of the next uh uh hour of this podcast but the uh the first stage is the battle plasti the second stage of the battle of buxar and this signing of this document takes place immediately after the Second Battle okay when the East India company has now basically subdued all opposition and North India we okay I think that's can we Circle back to that because I still want to know and this is a question that Indians ask all the time how is it that in numbers we outnumbered in strength of arms we were more powerful together and yet a group of adventurers managed to subdue and control a country as vast as India so can we go right right right right back to the first birth whales the Cradle whales of what would become the East India Company and this really fascinating man who I just love historian William called if we are going to be called what we do customer Smythe can</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = query_engine.query(\"acn you reproduce th etranscript for the first 30 seconds of the podcast?\")\n",
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "e05506c8-ab89-4536-b150-dae8bbfe8dd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<b>\n",
       "The hosts of the podcast are Anita Anand and William Durham pool. Anita Anand is an Indian in Britain, born in Essex, and has made most of her life in India.</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    2547.08 ms\n",
      "llama_print_timings:      sample time =      14.92 ms /    43 runs   (    0.35 ms per token,  2881.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1160.51 ms /    14 tokens (   82.89 ms per token,    12.06 tokens per second)\n",
      "llama_print_timings:        eval time =    6659.52 ms /    42 runs   (  158.56 ms per token,     6.31 tokens per second)\n",
      "llama_print_timings:       total time =    7919.42 ms\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"The hosts of thepodcast mention their name when they sign off ath the end. Can you tell me their names.one of them says That's all from me Anita Anand. and any other details about Anita?\")\n",
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "9a8a5361-7805-43f6-b2bf-7c656bb3fb7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(id_='a299f0a7-f2aa-4453-ab27-8c0aea0f4e27', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='6342d048795a6ef115d90eb0f0b8b6940172d15d4503dd6b1c33bdd055b58d49', text=\"[Music]\\nhello and welcome to a brand new podcast\\ncalled Empire with me Anita Anand and me\\nWilliam Durham pool now um in a funny\\nway we are both products of Empire I\\nmean you could say very simplistically\\nI'm the Indian in Britain I'm an of\\nIndian origin born in Essex but you know\\nnevertheless you know what I mean and\\nI'm I'm the Brit that's lived most made\\nout of life in India oh and why are we\\ndoing this why are we actually doing\\nthis well I think it's a very\\ninteresting moment to think about Empire\\num it's particularly an interesting\\nmoment to think about the British Empire\\nand the British Empire in India because\\nthis is something which I suddenly feel\\ngot sort of tucked in an attic in 1947.\\nthe British moved on they joined the\\nEuropean Community\\num they like to feel that they'd left\\ntheir Imperial past behind them they\\nturned into a different sort of nation\\nbut they certainly forgot about the most\\nimportant thing the Brits ever did in\\nworld history and suddenly My Generation\\ngoing to school would learn about the\\nthe Roman Empire we'd learn about all\\nsorts of empaths but we wouldn't learn\\nabout the British effort well I mean you\\nknow I've been to school dare I said a\\nbit more recently than you but we not\\nnot a sniff of it and it's really\\nstrange because you know we do the\\nsecond world war we do the\\ncommemorations of the first world war\\nthis is something that was as recent or\\nmore recent and was an enormous chapter\\nin in Britain's history but is it\\nbecause Empire's a dirty word these days\\nis that why well I think Emperor is a\\nvery controversial word and that's in a\\nsense another reason for doing the uh\\nthe podcast because for some people uh\\nparticularly I think a generation of\\nIndians and and other if you might call\\nthem children of Empire who whose\\nparents came here in the post-war period\\nthey're beginning to ask why are we here\\nwhat's what's happened and we've had you\\nknow people like satnam sangara writing\\nEmpire land we had Indians actually\\nThoreau writing major bestsellers uh are\\ncalled Inglorious Empire uh and people\\nare looking at this stuff again this is\\nthis is a period that where what was I\\nthink looked at very romantically\\nthrough Rose tinted spectacles through\\nMerchant Ivory films and so on is coming\\nup for critical evaluation and there's a\\nlot of pushback to that too I mean it's\\nfascinating because you know for a while\\nthis was a vacuum that was only\\ninhabited by Phil films so you know in\\nthe 70s you had the glorification of\\nEmpire and things like Zoo you could not\\nimagine Zulu being made today and in the\\n80s as you say it was all crinoline and\\nprettiness and Sundown as ladies and uh\\nunder parasols Passing Over The Lawns of\\nthe Bangalore club or playing croquet on\\nuh similar Lawns with smiling maharajas\\nand elephants swishing their tails and\\nlovely cut 1930s suits the idea that\\nEmpire was actually there like all\\nempaths obviously are for the benefit of\\nthe colonizer uh to send money and raw\\nmaterials back to the home country it\\nnever came into the whole merchandise\\nimage which was all puffing steam trains\\nunder uh under glorious night skies with\\nthe Taj Mahal's profile rising out of\\nthe Steam and and all that sort of stuff\\nyeah well I mean we're so in effect what\\nwe're trying to do in this in this\\npodcast is we're sort of setting fire to\\nthe Celluloid and trying to bring in the\\nfacts of what happened through a number\\nof um podcasts of different periods we\\nare going to be talking a lot about you\\nknow the Raj and India because is our\\nexpertise with Willie and I myself but\\neventually we we hope to cover all\\nmanner of Empires I'm very keen quite\\nquickly to bring in stuff about slavery\\nabout Africa about Scramble for Africa\\nbut also older Empires the Assyrians the\\nPersians the Roman Empires Byzantine\\nEmpire all this sort of stuff because it\\nseems to me that it covers a great\\nswathe of world history that explains a\\nlot of politics today I mean that's the\\nthing that I find really fascinating\\nthat we don't know it more because it\\ndoes look we're going to start though um\\nwith with Britain and India we're going\\nto start with the formation of the East\\nIndia Company in the 16th century all\\nthe way through the Raj eventually we're\\ngoing to take you to Independence and\\nthe partition of India which happened 75\\nyears ago this month by the way uh\\nAugust 2022 is the 75th anniversary and\\nWillie the East India Company I know has\\nbeen one of the great themes of your\\ncareer hasn't it I've actually been\\nworking on the East India Company for 20\\nyears and I started in 1999 and then\\nthis book was the key was published\\n2019.\\nand what's been fascinating for me is\\nsee how this subject which was right at\\nthe edge 20 years ago has moved into the\\ncenter of things now for two reasons one\\nis colonialism has moved to the central\\nthing suddenly the British have woken up\\nto the fact they had an Empire the lord\\nof the world is not happy about this\\nthat it isn't a wonderful Commonwealth\\nof Nations willingly following the the\\nlead of uh of our Queen and and our\\npeople but people who were conquered uh\\nlooted asset stripped shipped across\\nnations against their Wills that many\\nterrible things happen and the weird\\nthing that the British simply don't know\\nabout this it's not in our history\\nvictims we're not taught at school the\\nsecond thing that's happened of course\\nis that in the same period in the last\\n20 years we've suddenly been confronted\\nby these massive corporations who now\\ndominate our lives companies like Tesla\\nGoogle\\nFacebook\\nExxonMobil other massive corporations\\nthat operate in all the countries of the\\nworld Amazon uh can\\ncut around the tax laws and other laws\\nof individual nation states and play one\\nstate off against each other and\\nsuddenly we're in a situation as we were\\nwith the East India Company 200 years\\nago uh where a corporation is calling\\nthe shots and the nation-states are on\\nthe back foot now as you said in the\\nstory of these to the company ultimately\\nthe State wins and in 1858 the East\\nIndia Company is nationalized and the\\nBritish State takes over India and you\\nget the Raj but what is funny is that\\nwhile the Raj has dominated British\\nperceptions of their empire in India it\\nonly actually lasts 90 years it's a it's\\na free flash in the band fashion the pan\\nof Indian history also even a flash from\\nthe past in the history of British\\nimperialism right it lasts from 1858\\nuntil 1947 and this year we're\\ncelebrating the 75th anniversary of\\nIndian independence so it's almost as\\nlong now uh since we are in front of it\\nas we were yeah absolutely right it's 75\\nyears now in 15 years it'll be 90 years\\nand it'll be the same time as raj but\\nwhat is forgotten almost and this is why\\nfor the last 20 years I've been working\\non this is that like the the bit of the\\niceberg you can't see beneath the water\\nthere are precedes the beginning of the\\nRaj in 1858 no less than 250 years\\nwhen India is ruled from Britain but not\\nby the British government so this I mean\\nthis\\nin this scape is so Broad and as you say\\n250 years broad\\num but I would like us if you don't mind\\nWilliam to start in Wales obviously\\nobviously\\nif you don't mind\\num but but that's not the uh that's not\\nthe the animal you're talking about not\\nthe mammal no\\num I'm talking about a place in Wales\\nPowers Castle so\\nthis is a fascinating place\\nHarris Castle just tell us tell us why\\nthis is a really good place to start\\nthis story so purse Castle from the\\noutside looks about as English as\\nanywhere could possibly although it's\\nactually just over the border from\\nEngland within Wales\\nit has Tudor box Hedges it has wonderful\\nsort of Renaissance doorway and marble\\nuh it has these lovely Elizabethan\\nwindows and it has on the top\\ncrenellations\\nand it'd be hard to think of anything\\nmore British than this sort of fantastic\\nlooks like every boy's idea of a Ford\\nexactly it's a perfect sort of Castle\\nthat you know children building sound on\\non the beach on the beach\\nbut within the long Gallery at Powers\\nyou enter a completely different world\\nbecause you walk under a painting into a\\ngallery a Kazan or a treasury of what\\ncan only be described as Indian Loot and\\nloot of course is an Indian word lutner\\nthe blunder is a word that enters the\\nEnglish language at this period to\\ndescribe exactly the sort of objects\\nwhich are being filling this castle and\\nwhat you have is talwas uh swords\\nShields yeah Indian gowns little Ivory\\nchestmen Miniatures and one or two quite\\nin big objects of of Imperial planet of\\nreal you know International importance\\nthere's\\nleft on the battlefield of plastic was\\nthe battle which is always said to begin\\nthe British conquest of India it's the\\nfirst moment that the the Brits score a\\nmajor victory over an Indian power and\\ntake over a great chunk of territory by\\nforce\\nat the other end of the gallery you go\\nthrough the larchway and you end up in\\ntupu Sultan's Huntington why is that\\nthere because another member of the\\nfamily uh bought this tent after the\\ntipu sultan was was conquered by the\\nEast India Company in 1799 his Palace\\nburnt looted uh and the actual Loops is\\nhere in powers in actual fact if you\\ntake the whole thing together there is\\nmore Mughal loot more Mughal artworks\\nand objects in a private house in the\\nWelsh Countryside that exists in the\\nnational museum in Delhi or the national\\nmuseum in Pakistan or the great Lahore\\nMuseum or the national museum of\\nBangladesh or the museums in Afghanistan\\nand Iran uh and what's it doing here and\\nthe private house and although it's\\nlooked after by The National Trust the\\nobjects the museum is still the the uh\\nthe property of the of the family in\\nParis what's it doing there okay stop\\nteasing it you're asking the question\\nwhat is it doing there and who is the\\nfamily so I said when you enter this\\nGallery you walk under a picture and\\nthat picture\\nis the crucial key to the whole story\\nand it has a very unhelpful\\num caption beneath it it says the Sha\\nAlam conveying the gift of the dewani to\\nLord Clive now in in Britain and in\\nEngland there are very few people that\\nwould understand what that means the\\ngift of the duwari it sounds like a nice\\nDiwali present or yeah so Christmas or a\\nbirthday you know what and the picture\\nshows a big court scene with lots of\\nNobles on the right are the Indians the\\nmughals on the left are uh the Brits and\\nthe gentleman of the East India Company\\nin particular there are two men at the\\nfront uh surrounding the Mughal Emperor\\nwho's dressed dressed in cloth cloth of\\ngold and you you've got all of his\\nretinue behind him also very finely\\ndressed looking incredibly serious and\\nGrave although it's notable that the man\\nwho is the most richly dressed of them\\nall has his head bowed almost it looks\\nlike in supplication everybody the\\nBritish side their heads around up so\\nthey're sort of the bewigged gentleman\\nin their Crimson coats and their gold\\nbrocade and they are very much looking\\nup straight backed ramroded and the\\nIndian who is clearly in this picture\\neven if you didn't know the caption is a\\npotent Aid whose head is is bowed and\\nwell it might be bad because the\\npotentate who is the Mughal Emperor\\nwhose ancestors uh ruled over not just\\nall of India but Pakistan Bangladesh and\\nAfghanistan\\nuh he has just been humbled in battle\\ndefeated by the armies of the East India\\nCompany at the Battle of buxar in 1765\\nand he has just been forced to hand over\\nand you can see in the picture he's\\nhanding over a document to a man in the\\nred coat that coat is Robert Clive uh\\nIndia sometimes to the state stands\\noutside the foreign office and behind\\nDowning Street by the way really\\nirritates Indian diplomats I had no idea\\nbut we know a few do you remember um\\nthey have told us how disgusted they\\nwere to have to walk past well Clive of\\nIndia to get to their office this is the\\num this picture is the reason that\\npeople are disgusted because Clive of\\nIndia was not even the servant of the\\nBritish government and this is the\\ncrucial point he was the servant of a\\ncompany a corporation just like you know\\nElon Musk actually works for Tesla\\nhimself uh his own company uh not uh for\\nMr Biden he's not he's not observant to\\nthe American state he's a he has his own\\ncompany now this is exactly the\\nsituation Robert Clive Robert Club is\\nNot appointed by the government he's\\nappointed by the East India Company by\\nthe directors and what he's doing in\\nthis picture uh is he's taking control\\nafter the battle\\nof the three richest provinces of the\\nMughal Empire now we should say\\nimmediately that the the a the picture's\\nnot very good it's by a guy called\\nBenjamin West who is not a great painter\\nthe dome in the background which is this\\nsort of looming Palace actually looks as\\nas one of the critics said in the when\\nhe was hung in the Royal Academy more\\nlike the Dome of Saint Paul's than\\nanything you'd like to find in India and\\nwe learn in fact the bedroom West had\\nnever been to India and everything about\\nthis picture is actually a deception\\nbecause not only had Benjamin West never\\nbeen to India uh but this scene never\\nreally took place at least in the in the\\nway that shown here actually took place\\nthe the important document was\\ntransferred and signed in the private\\ntent of Clive after the battle uh he had\\nbasically put a gun against the defeated\\nEmperor's head and made him sign and\\naccording to one Mogul historian who was\\nthere he said the entire ceremony took\\nplace quicker than it would normally\\ntake to sell a jackass at a market\\nhashtag fake news as well yes with that\\ndope hashtag fake views I mean this is a\\nscandal upon Scandal so it is and so\\nit's a completely deceptive Edge and\\nthen and then you know to to\\num add insult to injury uh the caption\\nas we said is conveying the gift of the\\nDuane to Lord Clive that's like what's\\nthe Divani first of all we have to say\\nwhat is the dewani so the duwani is is\\nis basically the right to run the Duwan\\nwhich is the treasury uh or the or the\\nadministration and what it means is that\\nthis private company the East India\\nCompany is being given the right to run\\nthe finances of three Indian provinces\\nnow those provinces Bengal Bihar and\\nerisa where in the 18th century quite\\nsimply the richest place on Earth\\nthe Looms of those three provinces of\\nwhich there are about 1 million were\\nchurning out a great deal of the revenue\\nwhich meant that Mogul India was\\ncreating very nearly a quarter of the\\nworld's GDP while Britain is just just\\ncreating\\n1.8 percent\\nthis is because India had the great\\ntextile industry of its day you know\\nwhat would move in the 19th century\\npartly because of the events kicked off\\nat this moment by the gift of the Duane\\nas it's called Britain eventually gets\\ncontrol of uh of India and the Indian\\nIndustries eventually shut down and we\\nget the great industries of uh all the\\ntext our manufacturing moves to Lanka uh\\nLancashire and the north of England well\\nin the 19th century matches against\\ncalled cottonopolis the alternate name\\nfor yeah that's right and um but this is\\nthe moment before that episode this is\\nthe moment when an English company first\\ngets its hands on this incredibly Rich\\nterritory and it's done it in two stages\\nfirst to be and we'll we'll deal with\\nthis over the course of the next uh uh\\nhour of this podcast but the uh the\\nfirst stage is the battle plasti the\\nsecond stage of the battle of buxar and\\nthis signing of this document takes\\nplace immediately after the Second\\nBattle okay when the East India company\\nhas now basically subdued all opposition\\nand North India we okay I think that's\\ncan we Circle back to that because I\\nstill want to know and this is a\\nquestion that Indians ask all the time\\nhow is it that in numbers we outnumbered\\nin strength of arms we were more\\npowerful together and yet\\na group of adventurers managed to subdue\\nand control a country as vast as India\\nso can we go right right right right\\nback to the first birth whales the\\nCradle whales of what would become the\\nEast India Company and this really\\nfascinating man who I just love\\nhistorian William called if we are going\\nto be called what we do customer Smythe\\ncan we start with him\\nso these Tinder company is a company a\\ncorporation and like any company it\\nstarts up as a startup effectively uh\\nand uh the guy who has the idea the\\nfounder of this company is a man called\\ncustomer or auditor Smythe\\nso-called because he was an auditor in\\nother words an accountant uh who ended\\nup running the Customs\\num and ran the customs of London so he's\\na he's the kind of Richard Branson of\\nhis day or the Vijay Malia of his day\\nhe's an entrepreneurs made a lot of\\nmoney his dad was a big entrepreneur\\nbefore him he's inherited the money but\\nhe's hugely enlarged that\\nand so when the news comes in the late\\n1590s during now this is the year that\\num Elizabeth actually is about 80 years\\nold an old woman now everyone's slightly\\nwondering what's going to happen when\\nshe dies\\nuh this is also the uh incident need\\nthat Shakespeare is writing both Hamlet\\nand Julius Caesar which I saw last night\\nin the globe and if you had walked from\\nthe globe in 1599\\nover sutherbridge\\ninto what was then moorgate Fields not a\\ngrotty tube station in those days but uh\\nFields as the name suggests and in the\\nmiddle is a is a gorgeous black and\\nwhite Tudor building called the Founders\\nHall The customersmith Hires that for\\nthe day\\nand he calls all the rich investors the\\nthe people who you think can invest in\\nin his Venture and he says the Dutch had\\njust gone to the East Indies by the East\\nIndies he means what we now call\\nIndonesia not India in Italy right and\\nthe this the early days of the company's\\naimed not at all at India interestingly\\nbut at Indonesia and even Beyond The\\nSpice Islands on the edge of Papua New\\nGuinea\\nand he has the idea that if the Dutch\\ncan get there and buy spaces cutting out\\nall the middlemen cutting out the Arabs\\ncutting out the venetians cutting out\\nthe north Europeans\\nso can the English and so he he's he\\nappeals to their Tudor patriotism and he\\ncalls in a lot of people that we today\\nwere called Pirates because privateers\\nright okay the privateers the people who\\nhave been licensed by the state to loot\\nthe treasure ships uh moving Gold Silver\\nand other precious objects from South\\nAmerica to put Spain and Portugal again\\nI mean you you're so familiar but to\\nsomeone to somebody who is not that is\\nan astonishing thing that the state is\\ngiving full power to robbers ostensibly\\nto go and Rob well it's a it's actually\\nquite a familiar situation because in\\nthe immediate run-up to this England\\njust cut itself off from the continent\\nand in in this case uh uh not the uh not\\nthe of course the European Community\\nwhich hasn't been founded yet but the\\nReformation has cut it off from the\\nwhole of southern Europe and and\\ncountries like Spain and Portugal regard\\nuh England as a dangerous enemy State\\nand there's an awful lot of rivalry uh\\nthis is just after the Spanish Armada\\nthis is uh Philip II is just dead uh and\\nuh there's an awful lot of uh of dislike\\nof uh of Catholic Spain and and the and\\nthe popeish continent as they said but\\neven the Protestants are not necessarily\\nvery friendly towards the English and\\nthe Dutch who are Protestant who have\\njust broken free from Spain have made\\nthis pioneering visit to the spicelands\\nand made a fortune and the reason that\\nthe Dutch again the reason the Dutch are\\nso very important is because they've\\ndiscovered that route through the Cape\\nof Good Hope which makes their their\\ntraffic and their trade so very\\nlucrative well that route had been open\\nfor a while it'd been it had been found\\nfirst of all by Vasco de Gama\\num 50 years earlier and the whole\\nPortuguese Empire had come and gone uh\\nand the Dutch by better better sailing\\nboats better better Canon and deeper\\nPockets frankly overcome the Portuguese\\nEmpire and get to uh get to areas at the\\nvery edge of the Portuguese influence\\nwhere the spices grow and what sets off\\nthe whole thing is a visit of of Dutch\\nshippers to London to try and buy up\\nsome London shipping in order they can\\nmake more voyages and the customer smile\\nsays hang on guys we're taking our ships\\nyou cannot take the other British ship\\ncome over here and take our ships buy\\nour ships\\num we can do this ourselves so this\\nmeeting is called the same year that\\nJulius Caesar Hamlet first performed in\\nthe globe this meeting is called in this\\nblack and white Tudor Hall and we\\nbizarrely we have all the documents\\neverything for the East India Company is\\nkept right from this first meeting okay\\nand and that and one of the most\\ntantalizing documents that is is in this\\nis is the type of people who who sort of\\nsign in and sign up for this I mean\\nprivateers as you say but you know what\\nwe would call m s shareholders you know\\npeople from every Walk of Life correct\\nand so the document which is in the\\nBritish Library which I have a picture\\nof in my book The Anarchy shows the\\nfirst uh people signing up are the\\nGrandy's the the mayor of London who\\nputs in 300 quid somebody else puts in a\\nthousand but answer page 20 of this\\ndocument you have the people as you say\\nthe the ordinary conventors people who\\nsell wine and leather workers saddle\\nmakers saddle makers and they're putting\\nin 10 quid 5 quid and what has happened\\nis that Elizabeth England has invented\\nthis new mechanism for doing business\\nstop shares shouting shareholders yeah\\nthis is not idea which which you know is\\ninvented at this period before that you\\nhad guilds now guilds were a bit like\\nthis in that you know all the rulemakers\\nof suffer get together they pull their\\nresources and they go off and cut a deal\\nwith the uh tapestry makers in Holland\\nfor example or or Belgium uh but to be a\\nmember of Guild you had to be a wool\\nworker and have something to do with the\\nwool industry and that gave you access\\nto a beautiful Hall in the in the town\\nlike lavender more Burford or one of\\nthese lovely wool churches in uh in\\nEngland and uh what's new about the\\njoint stock company which is an idea\\nfirst invented in Elizabeth in England\\nin 1580 with the founding of the\\nmuscobee company\\nuh the Muscovy company was aimed at\\ntrade with Moscow and Russia it sold\\nFurs and this sort of stuff and and\\ngoods from the forests of the uh of the\\nthe step frankly\\num when they found that they had this\\nnew model and it and they say you know\\nit's not just\\nMerchants that can join anyone that\\nwants to put in some money can invest it\\nand they were going to share\\na percentage depending on how much they\\nput in so if they're a huge investor\\nthey get a huge profits if they're a\\nsmall investor they'll get a tiny share\\nbut this idea changes everything because\\nsuddenly you have the growth of\\ncompanies and these companies if they're\\npopular can raise vast sons of money and\\nif they fail they fail\\nand so what happens interestingly is\\nthat the Elizabethan state\\noutsources\\na lot of its Colonial activity two\\nmerchant companies not to the state\\nitself well I mean it cuts overheads you\\nit sort of makes sense if you're an\\nexchecker and you've got other things on\\nyour mind like Wars um you know or\\nthreatening borders this is the last\\nthing that you want to administer\\nAdministration is expensive so from this\\ntime you get the Muscovy company you get\\nthe Royal Africa company which is a\\nslaving company you get the Hudson Bay\\nCompany which still exists which which\\ndeals with all the Furs coming in from\\nthe northern United States or North\\nAmerica now in Canada\\nuh you get\\num\\nthe Rhode Island company which which\\ncontrols Rhode Island so and you get the\\nVirginia Company so you get all these\\ndifferent areas which are actually run\\nby Merchant corporations and investors\\nand so the East India Company is is is\\npart of this but it's not the first okay\\ncan I just ask I mean customers smile\\nwhat was he like I mean you said he was\\nlike Branson and sometimes these things\\nrise and fall particularly these days\\ncorporations on the Charisma of the\\nperson needing it what was he like do we\\nknow what he was like well we have a\\npicture of him which which shows this\\nsort of you know very uh Elizabethan guy\\nwith a a tall like a stovepipe hat a a\\ngoatee beard he's a he's a a well-to-do\\nnew Rich one generation old Fortune\\num and he's exactly the sort of man who\\nis rising up at this period full of\\nentrepreneurial energy quite ruthless\\nI mean we're talking Nouveau Rich so can\\nyou think of all those characters in\\nShakespeare plays from this period who\\nend up you know being Cast Away on\\nIslands in like the Tempest how\\ninteresting yeah so he's he's he's he's\\nhe's a London businessman he's connected\\nwith the with the privateers and he\\ngathers these guys into this meeting and\\nsays invest in my company we'll get some\\nspices and they do that so he says come\\nand invest in my company and and they do\\nand they do and as I said we have this\\ndocument which shows the large sum of\\nmoney which which is raised through this\\npublic meeting and we even have the a\\ndescription of the the young Richard\\nhacklett who who will go on to write\\nwonderful Travelers accounts and compile\\nthe accounts of other Travelers is hired\\nto to be the kind of notary keeping the\\nthe records and and and writing the\\nhistory they're aware that they're doing\\nsomething very historic so they employ a\\nbest-selling non-fiction writer to uh to\\nbe their own biographer right from the\\nbeginning and there's a great awareness\\nthat this is an important moment but I\\nmean it's but it's not it's not a\\nguarantee that this is going to work no\\nI mean and in fact you know there are\\ntwo very good reasons for for wondering\\nwhether this is a a good way to spend\\nyour money\\num first of all the man they hired to\\nsail the first voyage is a man called\\nSir James Lancaster and he's just come\\nback from a disastrous Voyage in the\\nsame area he's employed because he's the\\nonly man that's actually sailed there\\nbut he didn't sail back because he sank\\nhis ship and all his crew got eaten by\\ncannibals okay this is not as successful\\nuh First Choice you know he's the only\\nguy that does this so his first thing\\nyou know in the in the weeks after the\\nmeeting they've got their cash they\\ngather it from their shareholders we\\neven have notes saying you know X and Y\\nhasn't paid up yet and uh and they start\\ngetting kind of legal notices because\\nthey promise such as money they haven't\\ndelivered it but they go out and they go\\nto Deptford to look for a ship and the\\nfirst ship they find is a creek Hill\\nHulk called the mayflower the main floor\\nwhich they reject because they think\\nit's not seaworthy and obviously that\\nhas its own history going in a different\\ndirection right a little bit nobody tell\\nus the pilgrims one presumes but instead\\nthey buy a pirate ship and I'm not\\nmaking this up it's called The Scourge\\nof malice it sounds like Johnny Depp's\\nFlagship from uh I mean it does seem a\\nlittle obvious for privateers oh\\nlooking for a serious company exactly so\\nbeing good again that PR again looking\\nat posterity they changed them\\nimmediately from the scourge of malice\\nto the red dragon as if it's a nice sort\\nof Country Pub in the Welsh Countryside\\nnext to Powers Castle right and as you\\nsay you know there's no guarantee this\\nwill work and initially it doesn't they\\nset sail and they get become in the\\nchannel by freak uh freak Heat Wave and\\nthere's no\\num there's no Breeze I sit on in the\\nchannel and people have picnics and why\\nare they laughing at them are they\\nliterally pointing and laughing\\nthat's very funny but the breeze picks\\nup eventually and off they sail and to\\ntheir own surprise they ran the Cape of\\nGood Hope they actually uh apparently\\nperform a Shakespeare play on the on the\\nship which is wonderful what are the\\nDutch doing as they're going through\\ntheir their sea Lanes I mean are they\\njust do they know do they allow it or is\\nit just they're lucky because Lancaster\\nis just lucky this time well I mean I\\ndidn't have to ask permission from\\nanyone and this is armed uh armed\\nCommerce from the very beginning the\\ncharter that they ring out of the\\nElizabethan court allows them to wage\\nwar explicitly they'll fight their way\\nthrough if they have and they employ\\npeople you know with Canon and they\\nemploy archers and they employ all sorts\\nto to protect them so they realize that\\nyou know as as all Commerce is at this\\npoint that it's a risk and they've got\\nto take precautions\\nand they'd get eventually to the East\\nIndies by which we would say Java\\nIndonesia\\nand just as they're about to land they\\nsee a Portuguese Caravel coming in the\\nopposite direction and as there are\\nliterally a bunch of ex-pirates uh they\\njust land on the Portuguese ship and\\ntransfer its contents to their own hold\\nand sail home again okay so this is so\\nnot only does this require no effort but\\nalso no money so they come back with the\\nyou know the kitchen in their pockets\\nbut also Laden with Goods Laden with\\nGoods they they take an entire cargo of\\nnutmeg and spices and they sell it for\\none million pounds let's take a break\\nhere and we'll be back after this break\\nwith what happens to the Pirates when\\nthey come back with a million pounds\\n[Music]\\nyou're listening to Empire with me Anita\\nAnand\\nand me William you always leave this\\nvery pregnant pause as if you've\\nforgotten what your name is it is\\nwho me who me the world's Authority on\\nthe East India Company yes you and we\\nleft this story with um John Lancaster\\nwho does not have the most Sir James\\nLancaster I just drawn to his friends no\\nhe's not so James Lancaster uh who has\\nnot the most distinguished record at Sea\\nwho has lost uh\\nflotilla and many of his crew have been\\neaten on a previous Voyage but this time\\nlocks out royally or bigly as some may\\nsay in America because instead of having\\nto spend the hard invested cash of all\\nthe shareholders in in this nascent East\\nIndia company has bumped into a\\nPortuguese ship said I will have that it\\ntakes everything and goes home yep that\\nis literally it and that's very much the\\nspirit of the time and this you know\\nafter the after the Brits of have fallen\\nout with everybody in Europe again they\\nthey they have to take what they can get\\nand so that begins a very tricky 30\\nyears when they are competing against\\nthe Dutch now the Dutch with the first\\nInn the Dutch a new nation have\\nfantastic financial instruments they are\\nbrilliant financiers which is the Tudors\\nare not yet right they're they're\\nbeginners of this and because the Dutch\\nhave got deeper pockets and because\\nthey've got better ships and better sea\\ncaptains than Sir James Lancaster uh by\\n1630 30 years in the Brits basically\\nlost the competition uh the the real\\nsuccess story in the spice trade is now\\nthe Dutch and there's a series of\\ndisasters the amboina massacre being won\\nwhen the hood of Brits are captured and\\ntortured by the Dutch and eventually a\\ntreaty is signed and\\nas a sop as a sort of consolation prize\\nto the English they are given a muddy\\nisland in the Hudson River the other\\nside of the road called Manhattan oh\\nI've heard of it so that of course turns\\nout to be a rather good investment in\\nthe uh in the long term but in the short\\nterm this is rather a humiliation\\nand rather like a startup which has gone\\nawry and you know people investors\\nhaven't quite got their return but\\nthey're not giving up yet because you\\nknow they can see this there's still\\npotential the business model is\\nbasically re-rejigged in around 1630 to\\n1640. and what they decide to do is\\nbasically forget the spice trade leave\\nthat to the Dutch and I think already\\nthere are signs that the great days of\\nthe space Trade have passed that the\\nprices of spaces are going so the\\nEnglish is not completely\\num uh heartbroken to to no they can\\neither they can't they know that's not a\\nthing to fight over and what they\\nrealize is that the the new the new\\ntrade the really exciting trade is\\ntextiles so when we're talking about\\ntextiles coming you know from from\\nBengal and you're saying you know this\\nwas the majority of textiles were coming\\nfrom Bengal at this time what kind of\\ntextiles are we talking about so\\ninitially\\num the big Mogul Port is Surat which is\\nin Gujarat and Gujarat is the center of\\nthe cotton trade\\nuh by which and I got into us very\\nordinary I'm wearing a simple Cotton\\nwhite shirt at the moment and it's it\\nyou know it's it's unremarkable and\\ncheap but at the time it was considered\\nluxury brought up because it's it's very\\nsoft on the skin you wear it well\\ndarling thank you so much\\nand uh this was an ancient export of\\nIndia it was something at the time of\\nthe Romans uh Gujarati cotton was as\\nvaluable as silk gosh\\num and you know as as with spices you\\nknow you go to you go to waitrose or\\nSainsbury's and or Tesco's or little and\\nbuy a buy pepper now without thinking\\nabout it and uh it's not a it's not a\\nluxury product because the sheer\\nquantity the supplies meant that the the\\nprices sunk right down right the same\\nFactory of cotton that was was a luxury\\nuh is now something which is uh uh\\nunremarkable what were people wearing\\nbefore cotton well the Brits are wearing\\nwool uh which obviously is not suitable\\nfor the uh for the tropics uh and so\\nthey buy the cotton from Goodra and then\\nthey begin to get involved in all the\\nincredibly more exotic and exciting\\ntextiles being produced in Bengal\\nuh muslin which is incredibly fine often\\nsee-through uh silks uh wonderful\\nembroideries things called kalamkaris\\nwhich are painted and you hang them on\\nyour Tudor four poster bed and this is a\\nvery very good moment to be in the\\ntextile trade and it's also I I don't\\nthink this is a particularly planned\\nbecause you know there's no question\\nthat these in the company just lost\\nbattles against the Dutch but by moving\\nfrom the spice trade to the textile\\ntrade and moving from a focus on\\nIndonesia to India both these decisions\\nare very canny I mean it means you have\\nthe whole feel to yourself you have the\\nwhole field we're not quite the whole\\nfield because there are still a few\\nPortuguese uh enclaves like Goa uh uh\\nand the East India company has a few\\ndust offs with the with the Portuguese\\nright but nonetheless that they're in\\nearly and the important point is that\\nthe Moguls who now run India they've\\ncome down from what was Uzbekistan\\nthey've taken over uh the North and the\\nmiddle of India and by 1640 Shah Jahan\\nwho builds the Taj Mahal is on the uh on\\nthe throne and the Mogul Empire is\\nincredibly rich and Incredibly uh uh\\nincredibly willing to do trade but as\\nthese guys are Central Asian Nomads\\nthey're not interested particularly in\\nthe sea and there's no uh I mean there's\\na small there's a few ships but there's\\nno Navy as such uh that the Moguls\\ncontrol can I can I just I'm just draw\\nyour attention everyone's attention too\\nyou know you just said you know actually\\nthe mughals were so rich\\nthat it does not matter the British are\\nkind of a blip there is I mean a later\\num picture which is really informative\\nthis is this is jahangir as the\\nmillennial Sultan preferring the company\\nof sufis it's by bitchier the the\\npainter there and it is it's a\\nremarkable thing so you've got jahangir\\nsort of with a great Golden Disc behind\\nhim looking resplendent and important\\nand he's floating above him yeah and\\nhe's he's um he's handing over a one\\nwould presume a religious text to A Sufi\\nscholar I guess but in the left hand\\ncorner is a teeny tiny James the first\\nJames first looking looking at the\\nstoppers the Sufi to him and you've got\\nthis sort of sour expression on his face\\nand he's very really not very amused but\\nalso not important I mean so this is the\\nscale of what what India regarded\\nBritain as and the person below him is\\nis the painter\\nhis own self-portrait and and an artist\\nin the Mogul Court while the the Moguls\\nwere obsessed with art the status of\\nartists was very low so it's like like\\nputting a picture of I don't know\\num president macron next to a dustbid\\nman right uh I mean he's uh this is not\\na you know he's not he's been given the\\nleast honorable is it designed to be a\\npictorial insult or is it is it is it\\njust this is just how they say that's\\njust how they thought uh and and what\\nhas happened is that there's a picture\\nof James the first sitting there because\\nit's been given by one of the\\nambassadors and it's an exciting object\\nand the Mughal artist has copied it and\\nshoved it above his own picture I said\\nit's a remarkable thing so that's also\\nin your book but that again is very that\\nagain is very telling because the Brits\\nare from this yeah I mean the emperor\\nAkbar talks about uh uh the Northerners\\nas being like animals I mean these\\npeople regarded as semi-savage the Brits\\nthe Brits and all the other North\\nEuropeans okay so right okay so we've\\ngot the British apart from the old\\nSkirmish or around the image the English\\nthe English\\num but just the Portuguese snipping away\\nat their heels but otherwise they've\\npretty much got a clear run so from the\\nfrom the 1630s on the Brits have a very\\ngood chance of taking the Indian textile\\nmarket and exporting it around the globe\\nand they do this very successfully so\\nthat by the early 18th century you have\\nd industrialization as far as Mexico\\nbecause there's so much cheap Indian\\ncotton of a high quality and very low\\ncost being exported by the Brits to to\\nthe new are they are they exporting\\nstuff that's already being made or are\\nthey causing more stuff to be made they\\nare buying peace cotton as it's called\\nwhich otherwise bolts rolls of raw\\nmaterial uh they're not they're not in\\nmost cases commissioning anything\\ncommissioning sort of nice clothes no\\nthat it's it's the raw material and\\nthey're shipping it not just to Britain\\nbut all over the world and you know\\nthere's when you go to for example\\nlovely Renaissance palaces in Italy on\\nyour summer holidays you often see on\\nthe walls\\num Mogul Callum curries which are uh\\npresumably got there by the East India\\nCompany beautiful decorative items okay\\nso so this is lovely I mean you know\\nEngland gets its cotton and um the\\nWeavers get their money and they all\\nlived happily ever after well for a long\\ntime they do and both the Moguls and the\\nEast India Company Prosper spectacular\\nat this period\\nand everything goes quite well until\\norangzeb who is this uh Mughal Emperor\\nwho messes everything up he he takes too\\nmuch of the deck and he over expands too\\nfast to the South and also he irritates\\nall the Hindus by reimposing the jizio\\nattacks are non-believers attacks you\\nworship your own God and it's not an\\nIslamic God you pay attacks and\\nbasically since the time of Akbar the\\nMughal Empire had been a very successful\\ncollaborative\\ndeal between them the rajputamis who are\\nHindu who are are defeated in battle but\\nthen rather than being punished or being\\nlooted they are brought into the Mogul\\nfold and become the spearhead of\\nmogulamis so for quite a lot of the next\\num Century you find Hindu Mogul armies\\nattacking minor Muslim Sultans halfway\\ndown India in in the deck and so\\nahmednagar bijapur Golconda all these\\nlittle sultanates are attacked by Hindu\\narmies working for the Mogul so it's the\\nopposite in the sense of what you'd\\nexpect which is why today hey when what\\nfor example one goes to Rajasthan if you\\ngo to the town of bikaner there's a\\nwonderful Library where you find the\\nbest decony manuscripts which have been\\nlooted at this period from the middle of\\nIndia now come back to us aurangzeb is\\nmessing things up aurangzeb is messing\\nthings up and when he dies in 1707 the\\nEmpire begins to fall and this again was\\nwas something we talked about in an\\nearlier podcast the the jats the Sikhs\\nand the marathas are rising up\\nany of them could have taken the Moguls\\nout but in the end it's this odd\\ncharacter from out of out of town\\ncomes in comes to Delhi loots everything\\ntakes loads of loots\\namong among 8 000 wagons of other stuff\\nand\\nonce he's taken all the finance from\\nImperial treasury the Mughal Empire\\ndisintegrates where previously it had a\\nsingle unitary state beautifully\\nadministered uh by uh by local governors\\nin every corner of the Empire over\\nwhat's now four different countries\\num suddenly every town is\\nsemi-independent job\\nHyderabad you can't pay the soldiers you\\ncan't pay the administrations no one's\\ngoing to work the whole thing full spa\\nand in that churning if you like in in\\nthat extraordinary transformation of\\nIndia from a massive Empire to Tiny\\nself-governing States jostling up\\nagainst each other\\ntwo European corporations make merry one\\nis the East India Company based in\\nCalcutta Madras and Bombay but there's a\\nrival French company called the company\\ndesigned which is based in pondicherry\\nand chandanagar and they have Shadow\\nfactories opposite the English ones in\\nalmost every place what's the\\nrelationship I mean competition is one\\nthing but did it get violent between the\\ntwo so it's very hot it is it's very\\nhostile in the early 18th century uh\\nthere's a there's a global conflict\\nbetween France and England which\\nmanifests itself in first of all the\\nAustrian succession that eventually the\\nSeven Years War and and these are Global\\nconflicts the British fight the French\\nin in Lake Huron and in in the northern\\nUnited States in Canada remember that\\nlast American stuff with Daniel\\nDay-Lewis leaping over uh waterfalls and\\nall that sort of stuff in the Caribbean\\nas far away as the Philippines but also\\nyou know the Jacobite rebellion arming\\nthe Irish all this sort of stuff is\\ngoing on\\nin the middle of all this the English\\nand the French are fighting it out and\\nRobert Clive as a young man does a whole\\nseries of skirmishes called the carnatic\\nwars wait wait wait before you go into\\nthe carnatic was let us first of all\\njust explain who Robert Clive actually\\nwas because you know in in my mind and\\nin my schooling we only had Clive of\\nIndia as if he was some Noble who had\\nsort of beamed down into the history\\nbook but he was quite different wasn't\\nhe sure so Robert clove is exactly the\\nsort of guy who joins Easter to company\\nat this period he is from a sort of\\nposhish background he's a local Squire's\\nson social aspirations but not much\\nmoney\\nand a lot of these people are being\\nsigned up by the East India Company uh\\nbecause it's not a bad way of making a\\nliving at this period And if you are the\\nsort of uh minor Gentry that has high\\nsocial aspirations but simply doesn't\\nhave the money to support it anymore to\\nput one of your kids out to the East\\nIndia Company is a good option you're so\\nexciting you know like one son sometimes\\ngets into the priesthood if you don't\\nknow what to do with it but okay so\\nRobert but this is more like I suppose\\nputting one something to Goldman Sachs\\nokay but but he is by nature a\\ndelinquent he is indeed a delinquent and\\nthere is a whole lot of letters from his\\nuncle which survive which have him being\\nthe village Village bully he has\\nprotection rackets against Village\\nshopkeepers and Shropshire he breaks the\\nwindows of shopkeepers who don't pay up\\nhe even floods somebody's shop just just\\nout of spite so he's this sort of unruly\\nadolescent who is sent off by his uncle\\neventually to India where he signed up\\nas an accountant and of course being an\\nunruly delinquently hates it and twice\\nhe tries to shoot himself and twice for\\nvery reasons he fails but he regards\\nthis as sort of almost as a sort of\\ndivine\\nmandate that he's clearly been spared\\nfor great things and so when War breaks\\nout between France and England\\nhe signs up to become a soldier and this\\ndoes that unlike a candidacy to be\\nsomething that he's very bright Happy\\nStreet right up his street and he's not\\na professional Soldier he's not a\\nBritish Army but he takes to it like a\\nduck to water and he's trained up by\\nvarious Veterans of Culloden who have\\nnow come out to South India and together\\nClive and some of his mates basically\\noutwit the French company French company\\nis hobbled because it's very much\\nstate-run uh guys that can't quite make\\nit at court in Versailles a site losers\\nsent out and unlike the British company\\nwhich is a sort of libertarian thrusting\\nthat the hungry one hungry ruthless\\nambitious young men you get a lot of\\nsort of dim Aristocrats\\nso nobody knows what to do with and they\\nalso haven't got much freedom of\\nmovement everything has to go through\\nVersailles they don't get announced from\\nthe King because he's busy doing you\\nknow busy with his Mistresses and all\\nthat sort of stuff so the arrival of\\nClive coincides with the moment that the\\nEnglish East India Company clearly gets\\nan upper hand over the French\\nand Clive makes his first Fortune uh at\\nthis point comes back to England and\\ngoes into Parliament and almost\\nimmediately there's a scandal over the\\nfact that he's bribed everyone and quite\\nsoon having given somebody to his dad\\nand bought some land he finds his\\ncoffers which he thought would be an\\nafter Daron in fact they're exhausted\\nwithin three or four years\\nso he signs up at exactly the moment\\nwhen England and France are heading to\\nwar again and this is going to be the\\nconflict in that will finally break out\\nin 1756 to seven\\num that the Americans call the French\\nand Indian Wars\\num which we in Britain call the Seven\\nYears War right again the global\\nconflict between Britain and France in\\nall their different colonies and\\nterritories\\nand rather like the Iraq War a few years\\nago everything is set off by a\\nfalse piece of intelligence a document\\nis delivered to the East India Company\\nsaying that uh we've just seen that the\\nFrench are loading up an enormous\\nflotilla in their uh in their main base\\nPort Lorio\\nuh and it's clearly going off to bengal\\nand just set sail and there's\\ndescriptions of the number of Canon the\\nnumber of Warships that have gone the\\ndocument is not completely wrong in that\\nthere was a big potential but they've\\ngot the destination wrong in fact it's\\nheading to Canada\\noh and so when the Brits send out for a\\nrival Fleet they got that the company\\ngoes to the British Navy and says you\\nknow you've got to protect our interests\\nwe're about to be wiped off the face of\\nBengal uh the Royal Navy produces some\\nships Clive is recruited on the company\\nside and so you have a joint sort of uh\\nRoyal Navy and Marine and East India\\nCompany Expedition but they arrive in\\nMadras to find there's no friends\\nthere's no opposition at all because\\nthey've all gone off to Canada and\\nthey've sailed Halfway Around the World\\nthey've taken six months and there's no\\none there what the hell do they do Clive\\nyou know who might as well fire\\nyeah very nearly\\num sort of you know career almost ended\\nat this point having pressed this\\nExpedition is saved by a complete fluke\\njust at the same time as he's arriving\\nto the North in Calcutta a new governor\\nof Bengal is called siraj dialer and he\\nis another sort of angry Punk uh he's\\nyoung he's he's already fallen out with\\neverybody uh he's uh he's the Beloved\\nnephew of of man called Ali verdika nude\\ngoverned Bengal for years very well\\nbut he has none of aliverdicons tact\\ndiplomacy or sense of State he is famous\\nfor um thinking pleasure boats just to\\nwatch the have the fun of watching\\npeople drown he's a Serial Seducer of\\nwomen who takes women and warms them up\\nif they if he sounds like a total\\nscumbag he's a total scumbag and he\\nattacks Calcutta on the very uh\\nJustified ground that the Brits have\\nbeen\\nre-building the fortifications of\\nCalcutta without his permission he's the\\ngovernor they have to ask if they're\\ngoing to fortify that planning\\npermission very well exactly exactly\\nit's a planning permission dispute and\\num if he thinks that they must be arming\\nit against him because a lot of Bankers\\nhave recently arrived to Calcutta and\\nthe Brits are resisting them paying any\\ntaxes to Suraj in fact of course they\\nare arming against the French because\\nthey've been given this intelligence and\\nthe documents survive there's an entire\\nlife tiller on their way yeah on their\\nway so\\nwhen news arrives that Suraj has\\nattacked Calcutta and put many people\\ninto a guard house where they died of\\nheat and a hysteria in in something\\ncalled The Black Hole of Calcutta in\\n1756 when news comes that the city has\\nfallen and there's been this this\\napparent abuse of the survivors\\nClive suddenly has a job he said north\\nand he retakes Calcutta can we just on\\nthe Black Hole of Calcutta because I\\nmean that that is something that did\\ncome up when I was at school and uh it\\nwas hundreds of people were forced into\\nthis inhumane\\noxygen-less hole in the ground and left\\nto die men women and children it's a\\nvery pitiful story is that what happened\\nis that the truth of it well it's it's a\\nhugely disputed bit of History\\num that many people died is clear but\\nthe numbers seemed to have been hugely\\nexaggerated what happened was that when\\nthe Brits lost Calcutta a lot of them\\ngot very drunk and ran a mock and the\\nvarious people were shot\\nguards so again Suraj Dallas troops\\nquite reasonably said we can't have this\\nlot just running loose uh and taking pot\\nshots at us so they locked them in the\\nguard room\\nbut they lock\\nprobably about 60 people in this guard\\nroom it's a small space and about 30\\npeople come out alive so and\\nmy understanding having looked at the\\ndocuments and studied this is that\\nsomething happened that there was\\ndefinitely some extremely uh unfortunate\\nand avoidable deaths but it wasn't a\\nsort of dastardly plot to kill them all\\nabout the Brits misbehaved and this was\\nan attempt to keep unruly prisoners\\nunder lock and key until summer better\\nwas found for them I mean Sriracha\\ndollar is not somebody we want to stand\\nup for either I mean you know he's quite\\ncapable of doing uh yeah atrocities but\\nthe black hole of calcium\\nokay all right so this by the time it's\\narrived in Madras this story is already\\nand it's given a mandate isn't it it\\ngives Amanda in a reason and an\\nhonorability to what follows so the idea\\nis that Clive is going to liberate this\\ncaptured City he's going to vindicate\\nBritish honor and he's going to teach\\nthese Savages who've killed our poor\\nwomen and children a lesson\\nand he's got a big Royal Navy seller\\nwith some Marines he's taken on the East\\nIndia company's own\\num nascent mercenary Army who are the\\nsepoys who he's drained up a bit\\nand there's not many of them instead\\nnear the sea boys at this point there's\\nonly a few thousand\\num and they're really just jumped up\\nsecurity guards given a few muskets\\num and he arrives in Bengal and he\\nrecaptures Calcutta without really much\\nopposition it's not a a very difficult\\ntask given the armaments that he has\\nand he then gets the news that the\\nFrench uh have declared war on England\\nand the seven year war has begun so he\\nthen takes a second time which is\\nchandanagar the French Settlement that\\nis much more of a conflict there's a\\nenormous uh sea Battle in fact or or\\nusing naval ships on the hugely River\\nand uh a lot of people are killed on\\nboth sides and at this point having\\ntaken not just Calcutta but the French\\nheadquarters at chandanagar Clive writes\\nto his dad that he's heading home and\\nthat his name is made and he should be\\nnow again set up for Life set up for\\nLife yeah so Justice Clive is heading\\nback to Madras and planning to\\num you know cash in his chips and\\nanother nice little Victory a letter\\narrives that changes everything and the\\nletter is from a man called the jugged\\nset the banker to the world\\nand the jugged sets are like the\\nRothschilds of 19th century Europe they\\nare these uh incredibly Rich very\\npolitical Bankers they've invented a\\nvery clever system of transferring funds\\naround India at a time of disruption\\nin the old days the tax in Bengal which\\nkept the whole thing going because this\\nwas the rich area of of India would be\\nput onto a wagon a troop of soldiers\\nwould go with it and it would literally\\nMarch over land up the up the Ganges to\\nDelhi now with with war bands roaming\\naround that's no longer a possibility\\nand the jugged sets come up with this\\ncredit idea that basically you pay the\\ntax into our office in Calcutta and we\\nwill give you a chit and you can\\nwithdraw it in our office in Delhi it's\\nlike it's such a it feels like such a\\nmodern concept going into a federal\\nexpress and saying right send it send it\\nover money order but they it's exactly\\nthat but they they take 10 to 15 of the\\nof the taxes and given that this is you\\nknow the main source of money for the\\nMughal Empire they make a fortune very\\nvery quickly become the richest people\\nin Asia and and according to one Mogul\\nSource money flows into the coffers of\\nThe Jug at sets like the Ganges flows\\ninto the sea yeah and so these guys\\nright reach out to Clive and say we've\\nseen that you've just defeated uh Suraj\\nand taken back Calcutta we've got a\\nproposal for you we think Suraj Dada is\\na psycho he has threatened us he's\\nforced us to give him loans he's\\nthreatened to circumcise us and make us\\nMuslims and we're not standing for this\\nwhat we propose is that you attack\\nat his capital in murshidabad we will\\npay off his generals so they don't fight\\nand for that service sir we will pay you\\npersonally one million pounds and we\\nwill pay the company another million\\npounds what does what does that mean in\\nthose days what is one I mean it sounds\\nlike one million pounds what does it\\nactually means that Clive becomes the\\nrichest self-made man in Europe wow\\novernight it's a colossal offer and he\\nhas no authority to do this he's been\\nsent to fight the French which is done\\nuh but he takes this and and no one is\\nis going to say no to this kind of money\\nit's outrageous sums of money no one's\\never been offered this and the fact that\\nthe company's been offered a million two\\nmeans that Clive thinks that he can get\\naway with it so he goes north and for a\\nweek There's a terrible silence and he\\nwonders whether he's falling into a trap\\nbecause there's no letters reaching him\\nbut eventually he brazens it out and\\nthey meet at the battlefield of palashi\\nknown in English textbooks as Lassie\\npalaci is actually a type of tree a\\npalace trees this gorgeous orange tree\\nthat produces these wonderful bright\\nblossoms in April\\nuh but anyway there's Mangrove Groves\\nthere Clive camps for the night in the\\nmorning he finds the Mogul Army has\\nencircled him and there's a terrible\\nmoment when it looks like it's bitten\\noff more it's a trap he's bitten off\\nmore than he can true yeah and then the\\nfire from this Army supported by\\nincidentally a French contingent that\\nthey're very keen to wipe out the\\nEnglish\\nstarts and uh Clive's Army has to hide\\nthey CLI they hide on the banks of the\\nriver they hide in the mango Groves and\\nit looks like they're gonna have to leg\\nit back to Calcutta at night that's the\\nonly possible option\\nbut at the vital moment a monsoon storm\\nbreaks and there's a terrific downpour\\nand while the British remember to cover\\ntheir gunpowder with tarpaulins the\\nmogulstone you are joking literally This\\nCrew That's this one that basic thing\\ncould have turned history\\nso when the Mogul Calvary think that the\\nsame must have happened to the English\\nand the English calendar out of uh out\\nof uh commission immediately the monsoon\\nstorm ends the Cavalry the mogul's\\ncharge forward and they're met by a\\ncoral skating enormous volley from the\\nEnglish Canon killing all the leaders of\\nthe Cavalry and that's it and that's the\\nend of classy that is the Battle of\\nplastic at that point mere Jaffa who is\\nthe general in the pay of the junket\\nsets as well takes his half of the army\\nand marches off the battlefield the Raja\\ndialer realizes that he's been betrayed\\nplease off he is eventually captured\\nhacked bits and his mutilated body is\\nparaded on the back of a donkey through\\nmurshidabad the next day Clive walks\\ninto muridabad with The Jug it says and\\nliterally helps himself to everything in\\nthe treasury he stuffs his pockets and\\nyears later when he's called before\\nParliament rather like sort of Boris\\nJohnson he brazens it out and says my\\nlords there was a prostrate City at my\\nfeet the bankers waited on my pleasure\\nmy lords I was astonished at my own\\nmoderation oh For Heaven's Sake and\\neveryone laughs and he's off there and\\nthere's oh oh Clive but that explains\\nwhere we started Paris Castle stuff not\\nquite not right no no no nearly so what\\nhappens then is that Clive gets his\\nmillion and eight years later all the\\npeople that he has put into power as\\npuppies again rise up against English\\nbecause the English have behaved so\\nincredibly badly and basically you know\\nkilled the goose that was laying the\\ngolden egg in just eight years they lay\\nwaste to Bengal by asset stripping it\\nand there is another big uh Act of\\nresistance and not just the nawab of\\nBengal this time who's now called me a\\ncustomer man actually put in by by Clive\\nbut uh also the nawab of of avid which\\nis basically uttar Pradesh who's called\\nshuja odala and the Mughal Emperor\\nhimself\\nall meet at the Battle of buxar and they\\ntake on uh the East India Company but\\nagain the company has used the money\\nthat it's gathered to enormously\\nincrease the size of its sepoyamin it's\\nbought an enormous number of sepoys and\\nthere are now 40 000 trained up sea\\npoints trained in the latest European\\ntechniques of warfare horse artillery\\n18th century ballistics muskets Bandits\\nand it's a hard-fought battle but the\\neast Indian company's Army defeats all\\nthree of these armies Mass together\\nand this is the moment when the Clive\\nreturns to India and makes\\nand suddenly you find that the richest\\nprovinces of India three responses\\nBengal Bihar and erisa are signed over\\nnot to the British government\\nnot to the British army but to a private\\nCorporation the East India Company and\\nthat ladies and gentlemen is how you\\ntell a story and it's not it's not even\\nthe end is it it's just the end of the\\nbeginning this is now the moment that\\nthe company moves from being a trading\\norganization to suddenly it's an\\nimperial territorial power and if you\\nwant to know more about that do listen\\nto the next podcast that's all from me\\nAnita Anand and William\\n[Music]\\n\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n')"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "742191bc-c0ed-4d52-ae52-653446fc3b57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2547.08 ms\n",
      "llama_print_timings:      sample time =      28.11 ms /    80 runs   (    0.35 ms per token,  2846.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =   15813.43 ms /  2282 tokens (    6.93 ms per token,   144.31 tokens per second)\n",
      "llama_print_timings:        eval time =   13622.07 ms /    79 runs   (  172.43 ms per token,     5.80 tokens per second)\n",
      "llama_print_timings:       total time =   29626.51 ms\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<b>\n",
       "Anita wants to make this podcast because she feels it's an interesting moment to think about Empire, particularly the British Empire in India. She believes that the topic of Empire has been tucked away and forgotten in recent history, and she wants to bring attention to it through the podcast. Additionally, Anita notes that Empire is a controversial word, which adds another reason for making the podcast.</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = query_engine.query(\"Why does Anita want to make this podcast?\")\n",
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "c0ba1e68-e1c8-460b-adc9-f8410927ebb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2547.08 ms\n",
      "llama_print_timings:      sample time =      17.04 ms /    47 runs   (    0.36 ms per token,  2758.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =   15423.08 ms /  2313 tokens (    6.67 ms per token,   149.97 tokens per second)\n",
      "llama_print_timings:        eval time =    8074.19 ms /    46 runs   (  175.53 ms per token,     5.70 tokens per second)\n",
      "llama_print_timings:       total time =   23629.18 ms\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<b>\n",
       "In Parliament, Clive says, \"My lords, there was a prostrate City at my feet. The bankers waited on my pleasure. My lords, I was astonished at my own moderation.\"</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = query_engine.query(\"What does clive say in the parliament?\")\n",
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe84cc9-b4e2-47f6-9015-b8ada9eb37dd",
   "metadata": {},
   "source": [
    "'''\n",
    "(llamacpp) sankar@sankar-ml:~$ conda list\n",
    "# packages in environment at /home/sankar/anaconda3/envs/llamacpp:\n",
    "#\n",
    "# Name                    Version                   Build  Channel\n",
    "_libgcc_mutex             0.1                        main  \n",
    "_openmp_mutex             5.1                       1_gnu  \n",
    "accelerate                0.25.0                   pypi_0    pypi\n",
    "aiofiles                  23.2.1                   pypi_0    pypi\n",
    "aiohttp                   3.9.1                    pypi_0    pypi\n",
    "aiosignal                 1.3.1                    pypi_0    pypi\n",
    "aiostream                 0.5.2                    pypi_0    pypi\n",
    "altair                    5.2.0                    pypi_0    pypi\n",
    "annotated-types           0.6.0                    pypi_0    pypi\n",
    "anyio                     3.7.1                    pypi_0    pypi\n",
    "argon2-cffi               21.3.0             pyhd3eb1b0_0  \n",
    "argon2-cffi-bindings      21.2.0          py311h5eee18b_0  \n",
    "asgiref                   3.7.2                    pypi_0    pypi\n",
    "asttokens                 2.0.5              pyhd3eb1b0_0  \n",
    "async-lru                 2.0.4           py311h06a4308_0  \n",
    "attrs                     23.1.0          py311h06a4308_0  \n",
    "babel                     2.11.0          py311h06a4308_0  \n",
    "backcall                  0.2.0              pyhd3eb1b0_0  \n",
    "backoff                   2.2.1                    pypi_0    pypi\n",
    "bcrypt                    4.1.1                    pypi_0    pypi\n",
    "beautifulsoup4            4.12.2          py311h06a4308_0  \n",
    "bitsandbytes              0.41.3.post2             pypi_0    pypi\n",
    "blas                      1.0                         mkl  \n",
    "bleach                    4.1.0              pyhd3eb1b0_0  \n",
    "bottleneck                1.3.5           py311hbed6279_0  \n",
    "brotlipy                  0.7.0           py311h5eee18b_1002  \n",
    "bzip2                     1.0.8                h7b6447c_0  \n",
    "ca-certificates           2023.08.22           h06a4308_0  \n",
    "cachetools                5.3.2                    pypi_0    pypi\n",
    "certifi                   2023.11.17      py311h06a4308_0  \n",
    "cffi                      1.15.1          py311h5eee18b_3  \n",
    "charset-normalizer        2.0.4              pyhd3eb1b0_0  \n",
    "chroma-hnswlib            0.7.3                    pypi_0    pypi\n",
    "chromadb                  0.4.18                   pypi_0    pypi\n",
    "click                     8.1.7                    pypi_0    pypi\n",
    "colorama                  0.4.6                    pypi_0    pypi\n",
    "coloredlogs               15.0.1                   pypi_0    pypi\n",
    "comm                      0.1.2           py311h06a4308_0  \n",
    "contourpy                 1.2.0                    pypi_0    pypi\n",
    "cryptography              41.0.3          py311hdda0065_0  \n",
    "cuda-cudart               11.8.89                       0    nvidia\n",
    "cuda-cupti                11.8.87                       0    nvidia\n",
    "cuda-libraries            11.8.0                        0    nvidia\n",
    "cuda-nvrtc                11.8.89                       0    nvidia\n",
    "cuda-nvtx                 11.8.86                       0    nvidia\n",
    "cuda-runtime              11.8.0                        0    nvidia\n",
    "cudatoolkit               11.8.0               h6a678d5_0    anaconda\n",
    "cycler                    0.12.1                   pypi_0    pypi\n",
    "dataclasses-json          0.6.3                    pypi_0    pypi\n",
    "debugpy                   1.6.7           py311h6a678d5_0  \n",
    "decorator                 5.1.1              pyhd3eb1b0_0  \n",
    "defusedxml                0.7.1              pyhd3eb1b0_0  \n",
    "deprecated                1.2.14                   pypi_0    pypi\n",
    "diskcache                 5.6.3                    pypi_0    pypi\n",
    "distro                    1.8.0                    pypi_0    pypi\n",
    "executing                 0.8.3              pyhd3eb1b0_0  \n",
    "fastapi                   0.104.1                  pypi_0    pypi\n",
    "ffmpeg                    4.3                  hf484d3e_0    pytorch\n",
    "ffmpy                     0.3.1                    pypi_0    pypi\n",
    "filelock                  3.9.0           py311h06a4308_0  \n",
    "flatbuffers               23.5.26                  pypi_0    pypi\n",
    "fonttools                 4.47.0                   pypi_0    pypi\n",
    "freetype                  2.12.1               h4a9f257_0  \n",
    "frozenlist                1.4.0                    pypi_0    pypi\n",
    "fsspec                    2023.12.1                pypi_0    pypi\n",
    "giflib                    5.2.1                h5eee18b_3  \n",
    "gmp                       6.2.1                h295c915_3  \n",
    "gmpy2                     2.1.2           py311hc9b5ff0_0  \n",
    "gnutls                    3.6.15               he1e5248_0  \n",
    "google-auth               2.25.2                   pypi_0    pypi\n",
    "googleapis-common-protos  1.62.0                   pypi_0    pypi\n",
    "gradio                    4.12.0                   pypi_0    pypi\n",
    "gradio-client             0.8.0                    pypi_0    pypi\n",
    "greenlet                  3.0.2                    pypi_0    pypi\n",
    "grpcio                    1.60.0                   pypi_0    pypi\n",
    "h11                       0.14.0                   pypi_0    pypi\n",
    "httpcore                  1.0.2                    pypi_0    pypi\n",
    "httptools                 0.6.1                    pypi_0    pypi\n",
    "httpx                     0.25.2                   pypi_0    pypi\n",
    "huggingface-hub           0.19.4                   pypi_0    pypi\n",
    "humanfriendly             10.0                     pypi_0    pypi\n",
    "idna                      3.4             py311h06a4308_0  \n",
    "importlib-metadata        6.11.0                   pypi_0    pypi\n",
    "importlib-resources       6.1.1                    pypi_0    pypi\n",
    "intel-openmp              2023.1.0         hdb19cb5_46305  \n",
    "ipykernel                 6.25.0          py311h92b7b1e_0  \n",
    "ipython                   8.15.0          py311h06a4308_0  \n",
    "jedi                      0.18.1          py311h06a4308_1  \n",
    "jinja2                    3.1.2           py311h06a4308_0  \n",
    "joblib                    1.3.2                    pypi_0    pypi\n",
    "jpeg                      9e                   h5eee18b_1  \n",
    "json5                     0.9.6              pyhd3eb1b0_0  \n",
    "jsonpatch                 1.33                     pypi_0    pypi\n",
    "jsonpointer               2.4                      pypi_0    pypi\n",
    "jsonschema                4.19.2          py311h06a4308_0  \n",
    "jsonschema-specifications 2023.7.1        py311h06a4308_0  \n",
    "jupyter-lsp               2.2.0           py311h06a4308_0  \n",
    "jupyter_client            8.6.0           py311h06a4308_0  \n",
    "jupyter_core              5.5.0           py311h06a4308_0  \n",
    "jupyter_events            0.8.0           py311h06a4308_0  \n",
    "jupyter_server            2.10.0          py311h06a4308_0  \n",
    "jupyter_server_terminals  0.4.4           py311h06a4308_1  \n",
    "jupyterlab                4.0.8           py311h06a4308_0  \n",
    "jupyterlab_pygments       0.1.2                      py_0  \n",
    "jupyterlab_server         2.25.1          py311h06a4308_0  \n",
    "kiwisolver                1.4.5                    pypi_0    pypi\n",
    "kubernetes                28.1.0                   pypi_0    pypi\n",
    "lame                      3.100                h7b6447c_0  \n",
    "langchain                 0.0.344                  pypi_0    pypi\n",
    "langchain-core            0.0.13                   pypi_0    pypi\n",
    "langsmith                 0.0.75                   pypi_0    pypi\n",
    "lcms2                     2.12                 h3be6417_0  \n",
    "ld_impl_linux-64          2.38                 h1181459_1  \n",
    "lerc                      3.0                  h295c915_0  \n",
    "libcublas                 11.11.3.6                     0    nvidia\n",
    "libcufft                  10.9.0.58                     0    nvidia\n",
    "libcufile                 1.7.2.10                      0    nvidia\n",
    "libcurand                 10.3.3.141                    0    nvidia\n",
    "libcusolver               11.4.1.48                     0    nvidia\n",
    "libcusparse               11.7.5.86                     0    nvidia\n",
    "libdeflate                1.17                 h5eee18b_0  \n",
    "libffi                    3.4.4                h6a678d5_0  \n",
    "libgcc-ng                 11.2.0               h1234567_1  \n",
    "libgomp                   11.2.0               h1234567_1  \n",
    "libiconv                  1.16                 h7f8727e_2  \n",
    "libidn2                   2.3.4                h5eee18b_0  \n",
    "libnpp                    11.8.0.86                     0    nvidia\n",
    "libnvjpeg                 11.9.0.86                     0    nvidia\n",
    "libpng                    1.6.39               h5eee18b_0  \n",
    "libsodium                 1.0.18               h7b6447c_0  \n",
    "libstdcxx-ng              11.2.0               h1234567_1  \n",
    "libtasn1                  4.19.0               h5eee18b_0  \n",
    "libtiff                   4.5.1                h6a678d5_0  \n",
    "libunistring              0.9.10               h27cfd23_0  \n",
    "libuuid                   1.41.5               h5eee18b_0  \n",
    "libwebp                   1.2.4                h11a3e52_1  \n",
    "libwebp-base              1.2.4                h5eee18b_1  \n",
    "llama-cpp-python          0.2.20                   pypi_0    pypi\n",
    "llama-index               0.9.13                   pypi_0    pypi\n",
    "lz4-c                     1.9.4                h6a678d5_0  \n",
    "markdown-it-py            3.0.0                    pypi_0    pypi\n",
    "markupsafe                2.1.1           py311h5eee18b_0  \n",
    "marshmallow               3.20.1                   pypi_0    pypi\n",
    "matplotlib                3.8.2                    pypi_0    pypi\n",
    "matplotlib-inline         0.1.6           py311h06a4308_0  \n",
    "mdurl                     0.1.2                    pypi_0    pypi\n",
    "mistune                   2.0.4           py311h06a4308_0  \n",
    "mkl                       2023.1.0         h213fc3f_46343  \n",
    "mkl-service               2.4.0           py311h5eee18b_1  \n",
    "mkl_fft                   1.3.6           py311ha02d727_1  \n",
    "mkl_random                1.2.2           py311ha02d727_1  \n",
    "mmh3                      4.0.1                    pypi_0    pypi\n",
    "monotonic                 1.6                      pypi_0    pypi\n",
    "mpc                       1.1.0                h10f8cd9_1  \n",
    "mpfr                      4.0.2                hb69a4c5_1  \n",
    "mpmath                    1.3.0           py311h06a4308_0  \n",
    "multidict                 6.0.4                    pypi_0    pypi\n",
    "mypy-extensions           1.0.0                    pypi_0    pypi\n",
    "nbclient                  0.8.0           py311h06a4308_0  \n",
    "nbconvert                 7.10.0          py311h06a4308_0  \n",
    "nbformat                  5.9.2           py311h06a4308_0  \n",
    "ncurses                   6.4                  h6a678d5_0  \n",
    "nest-asyncio              1.5.8                    pypi_0    pypi\n",
    "nettle                    3.7.3                hbbd107a_1  \n",
    "networkx                  3.1             py311h06a4308_0  \n",
    "nltk                      3.8.1                    pypi_0    pypi\n",
    "notebook                  7.0.6           py311h06a4308_0  \n",
    "notebook-shim             0.2.3           py311h06a4308_0  \n",
    "numexpr                   2.8.4           py311h65dcdc2_1  \n",
    "numpy                     1.25.2          py311h08b1b3b_0  \n",
    "numpy-base                1.25.2          py311hf175353_0  \n",
    "oauthlib                  3.2.2                    pypi_0    pypi\n",
    "onnxruntime               1.16.3                   pypi_0    pypi\n",
    "openai                    1.3.8                    pypi_0    pypi\n",
    "openh264                  2.1.1                h4ff587b_0  \n",
    "openssl                   3.0.12               h7f8727e_0  \n",
    "opentelemetry-api         1.21.0                   pypi_0    pypi\n",
    "opentelemetry-exporter-otlp-proto-common 1.21.0                   pypi_0    pypi\n",
    "opentelemetry-exporter-otlp-proto-grpc 1.21.0                   pypi_0    pypi\n",
    "opentelemetry-instrumentation 0.42b0                   pypi_0    pypi\n",
    "opentelemetry-instrumentation-asgi 0.42b0                   pypi_0    pypi\n",
    "opentelemetry-instrumentation-fastapi 0.42b0                   pypi_0    pypi\n",
    "opentelemetry-proto       1.21.0                   pypi_0    pypi\n",
    "opentelemetry-sdk         1.21.0                   pypi_0    pypi\n",
    "opentelemetry-semantic-conventions 0.42b0                   pypi_0    pypi\n",
    "opentelemetry-util-http   0.42b0                   pypi_0    pypi\n",
    "orjson                    3.9.10                   pypi_0    pypi\n",
    "overrides                 7.4.0           py311h06a4308_0  \n",
    "packaging                 23.2                     pypi_0    pypi\n",
    "pandas                    2.0.3           py311ha02d727_0  \n",
    "pandocfilters             1.5.0              pyhd3eb1b0_0  \n",
    "parso                     0.8.3              pyhd3eb1b0_0  \n",
    "pexpect                   4.8.0              pyhd3eb1b0_3  \n",
    "pickleshare               0.7.5           pyhd3eb1b0_1003  \n",
    "pillow                    9.4.0           py311h6a678d5_0  \n",
    "pip                       23.2.1          py311h06a4308_0  \n",
    "platformdirs              3.10.0          py311h06a4308_0  \n",
    "posthog                   3.1.0                    pypi_0    pypi\n",
    "prometheus_client         0.14.1          py311h06a4308_0  \n",
    "prompt-toolkit            3.0.36          py311h06a4308_0  \n",
    "protobuf                  4.25.1                   pypi_0    pypi\n",
    "psutil                    5.9.0           py311h5eee18b_0  \n",
    "ptyprocess                0.7.0              pyhd3eb1b0_2  \n",
    "pulsar-client             3.3.0                    pypi_0    pypi\n",
    "pure_eval                 0.2.2              pyhd3eb1b0_0  \n",
    "pyasn1                    0.5.1                    pypi_0    pypi\n",
    "pyasn1-modules            0.3.0                    pypi_0    pypi\n",
    "pycparser                 2.21               pyhd3eb1b0_0  \n",
    "pydantic                  2.5.3                    pypi_0    pypi\n",
    "pydantic-core             2.14.6                   pypi_0    pypi\n",
    "pydub                     0.25.1                   pypi_0    pypi\n",
    "pygments                  2.15.1          py311h06a4308_1  \n",
    "pyopenssl                 23.2.0          py311h06a4308_0  \n",
    "pyparsing                 3.1.1                    pypi_0    pypi\n",
    "pypika                    0.48.9                   pypi_0    pypi\n",
    "pysocks                   1.7.1           py311h06a4308_0  \n",
    "python                    3.11.5               h955ad1f_0  \n",
    "python-dateutil           2.8.2              pyhd3eb1b0_0  \n",
    "python-dotenv             1.0.0                    pypi_0    pypi\n",
    "python-fastjsonschema     2.16.2          py311h06a4308_0  \n",
    "python-json-logger        2.0.7           py311h06a4308_0  \n",
    "python-multipart          0.0.6                    pypi_0    pypi\n",
    "python-tzdata             2023.3             pyhd3eb1b0_0  \n",
    "pytorch                   2.0.1           py3.11_cuda11.8_cudnn8.7.0_0    pytorch\n",
    "pytorch-cuda              11.8                 h7e8668a_5    pytorch\n",
    "pytorch-mutex             1.0                        cuda    pytorch\n",
    "pytz                      2022.7          py311h06a4308_0  \n",
    "pyyaml                    6.0.1           py311h5eee18b_0  \n",
    "pyzmq                     25.1.0          py311h6a678d5_0  \n",
    "readline                  8.2                  h5eee18b_0  \n",
    "referencing               0.30.2          py311h06a4308_0  \n",
    "regex                     2023.10.3                pypi_0    pypi\n",
    "requests                  2.31.0          py311h06a4308_0  \n",
    "requests-oauthlib         1.3.1                    pypi_0    pypi\n",
    "rfc3339-validator         0.1.4           py311h06a4308_0  \n",
    "rfc3986-validator         0.1.1           py311h06a4308_0  \n",
    "rich                      13.7.0                   pypi_0    pypi\n",
    "rpds-py                   0.10.6          py311hb02cf49_0  \n",
    "rsa                       4.9                      pypi_0    pypi\n",
    "safetensors               0.4.1                    pypi_0    pypi\n",
    "scikit-learn              1.3.2                    pypi_0    pypi\n",
    "scipy                     1.11.4                   pypi_0    pypi\n",
    "semantic-version          2.10.0                   pypi_0    pypi\n",
    "send2trash                1.8.2           py311h06a4308_0  \n",
    "sentence-transformers     2.2.2                    pypi_0    pypi\n",
    "sentencepiece             0.1.99                   pypi_0    pypi\n",
    "setuptools                68.0.0          py311h06a4308_0  \n",
    "shellingham               1.5.4                    pypi_0    pypi\n",
    "six                       1.16.0             pyhd3eb1b0_1  \n",
    "sniffio                   1.2.0           py311h06a4308_1  \n",
    "soupsieve                 2.5             py311h06a4308_0  \n",
    "sqlalchemy                2.0.23                   pypi_0    pypi\n",
    "sqlite                    3.41.2               h5eee18b_0  \n",
    "stack_data                0.2.0              pyhd3eb1b0_0  \n",
    "starlette                 0.27.0                   pypi_0    pypi\n",
    "sympy                     1.11.1          py311h06a4308_0  \n",
    "tbb                       2021.8.0             hdb19cb5_0  \n",
    "tenacity                  8.2.3                    pypi_0    pypi\n",
    "terminado                 0.17.1          py311h06a4308_0  \n",
    "threadpoolctl             3.2.0                    pypi_0    pypi\n",
    "tiktoken                  0.5.2                    pypi_0    pypi\n",
    "tinycss2                  1.2.1           py311h06a4308_0  \n",
    "tk                        8.6.12               h1ccaba5_0  \n",
    "tokenizers                0.15.0                   pypi_0    pypi\n",
    "tomlkit                   0.12.0                   pypi_0    pypi\n",
    "toolz                     0.12.0                   pypi_0    pypi\n",
    "torchaudio                2.0.2               py311_cu118    pytorch\n",
    "torchtriton               2.0.0                     py311    pytorch\n",
    "torchvision               0.15.2              py311_cu118    pytorch\n",
    "tornado                   6.3.3           py311h5eee18b_0  \n",
    "tqdm                      4.66.1                   pypi_0    pypi\n",
    "traitlets                 5.7.1           py311h06a4308_0  \n",
    "transformers              4.35.2                   pypi_0    pypi\n",
    "typer                     0.9.0                    pypi_0    pypi\n",
    "typing-extensions         4.9.0                    pypi_0    pypi\n",
    "typing-inspect            0.9.0                    pypi_0    pypi\n",
    "tzdata                    2023c                h04d1e81_0  \n",
    "urllib3                   1.26.16         py311h06a4308_0  \n",
    "uvicorn                   0.24.0.post1             pypi_0    pypi\n",
    "uvloop                    0.19.0                   pypi_0    pypi\n",
    "watchfiles                0.21.0                   pypi_0    pypi\n",
    "wcwidth                   0.2.5              pyhd3eb1b0_0  \n",
    "webencodings              0.5.1           py311h06a4308_1  \n",
    "websocket-client          0.58.0          py311h06a4308_4  \n",
    "websockets                11.0.3                   pypi_0    pypi\n",
    "wheel                     0.38.4          py311h06a4308_0  \n",
    "wrapt                     1.16.0                   pypi_0    pypi\n",
    "xz                        5.4.2                h5eee18b_0  \n",
    "yaml                      0.2.5                h7b6447c_0  \n",
    "yarl                      1.9.4                    pypi_0    pypi\n",
    "youtube-transcript-api    0.6.1                    pypi_0    pypi\n",
    "zeromq                    4.3.4                h2531618_0  \n",
    "zipp                      3.17.0                   pypi_0    pypi\n",
    "zlib                      1.2.13               h5eee18b_0  \n",
    "zstd                      1.5.5                hc292b87_0  \n",
    "(llamacpp) sankar@sankar-ml:~$ pip list\n",
    "Package                                  Version\n",
    "---------------------------------------- ------------\n",
    "accelerate                               0.25.0\n",
    "aiofiles                                 23.2.1\n",
    "aiohttp                                  3.9.1\n",
    "aiosignal                                1.3.1\n",
    "aiostream                                0.5.2\n",
    "altair                                   5.2.0\n",
    "annotated-types                          0.6.0\n",
    "anyio                                    3.7.1\n",
    "argon2-cffi                              21.3.0\n",
    "argon2-cffi-bindings                     21.2.0\n",
    "asgiref                                  3.7.2\n",
    "asttokens                                2.0.5\n",
    "async-lru                                2.0.4\n",
    "attrs                                    23.1.0\n",
    "Babel                                    2.11.0\n",
    "backcall                                 0.2.0\n",
    "backoff                                  2.2.1\n",
    "bcrypt                                   4.1.1\n",
    "beautifulsoup4                           4.12.2\n",
    "bitsandbytes                             0.41.3.post2\n",
    "bleach                                   4.1.0\n",
    "Bottleneck                               1.3.5\n",
    "brotlipy                                 0.7.0\n",
    "cachetools                               5.3.2\n",
    "certifi                                  2023.11.17\n",
    "cffi                                     1.15.1\n",
    "charset-normalizer                       2.0.4\n",
    "chroma-hnswlib                           0.7.3\n",
    "chromadb                                 0.4.18\n",
    "click                                    8.1.7\n",
    "colorama                                 0.4.6\n",
    "coloredlogs                              15.0.1\n",
    "comm                                     0.1.2\n",
    "contourpy                                1.2.0\n",
    "cryptography                             41.0.3\n",
    "cycler                                   0.12.1\n",
    "dataclasses-json                         0.6.3\n",
    "debugpy                                  1.6.7\n",
    "decorator                                5.1.1\n",
    "defusedxml                               0.7.1\n",
    "Deprecated                               1.2.14\n",
    "diskcache                                5.6.3\n",
    "distro                                   1.8.0\n",
    "executing                                0.8.3\n",
    "fastapi                                  0.104.1\n",
    "fastjsonschema                           2.16.2\n",
    "ffmpy                                    0.3.1\n",
    "filelock                                 3.9.0\n",
    "flatbuffers                              23.5.26\n",
    "fonttools                                4.47.0\n",
    "frozenlist                               1.4.0\n",
    "fsspec                                   2023.12.1\n",
    "gmpy2                                    2.1.2\n",
    "google-auth                              2.25.2\n",
    "googleapis-common-protos                 1.62.0\n",
    "gradio                                   4.12.0\n",
    "gradio_client                            0.8.0\n",
    "greenlet                                 3.0.2\n",
    "grpcio                                   1.60.0\n",
    "h11                                      0.14.0\n",
    "httpcore                                 1.0.2\n",
    "httptools                                0.6.1\n",
    "httpx                                    0.25.2\n",
    "huggingface-hub                          0.19.4\n",
    "humanfriendly                            10.0\n",
    "idna                                     3.4\n",
    "importlib-metadata                       6.11.0\n",
    "importlib-resources                      6.1.1\n",
    "ipykernel                                6.25.0\n",
    "ipython                                  8.15.0\n",
    "jedi                                     0.18.1\n",
    "Jinja2                                   3.1.2\n",
    "joblib                                   1.3.2\n",
    "json5                                    0.9.6\n",
    "jsonpatch                                1.33\n",
    "jsonpointer                              2.4\n",
    "jsonschema                               4.19.2\n",
    "jsonschema-specifications                2023.7.1\n",
    "jupyter_client                           8.6.0\n",
    "jupyter_core                             5.5.0\n",
    "jupyter-events                           0.8.0\n",
    "jupyter-lsp                              2.2.0\n",
    "jupyter_server                           2.10.0\n",
    "jupyter_server_terminals                 0.4.4\n",
    "jupyterlab                               4.0.8\n",
    "jupyterlab-pygments                      0.1.2\n",
    "jupyterlab_server                        2.25.1\n",
    "kiwisolver                               1.4.5\n",
    "kubernetes                               28.1.0\n",
    "langchain                                0.0.344\n",
    "langchain-core                           0.0.13\n",
    "langsmith                                0.0.75\n",
    "llama_cpp_python                         0.2.20\n",
    "llama-index                              0.9.13\n",
    "markdown-it-py                           3.0.0\n",
    "MarkupSafe                               2.1.1\n",
    "marshmallow                              3.20.1\n",
    "matplotlib                               3.8.2\n",
    "matplotlib-inline                        0.1.6\n",
    "mdurl                                    0.1.2\n",
    "mistune                                  2.0.4\n",
    "mkl-fft                                  1.3.6\n",
    "mkl-random                               1.2.2\n",
    "mkl-service                              2.4.0\n",
    "mmh3                                     4.0.1\n",
    "monotonic                                1.6\n",
    "mpmath                                   1.3.0\n",
    "multidict                                6.0.4\n",
    "mypy-extensions                          1.0.0\n",
    "nbclient                                 0.8.0\n",
    "nbconvert                                7.10.0\n",
    "nbformat                                 5.9.2\n",
    "nest-asyncio                             1.5.8\n",
    "networkx                                 3.1\n",
    "nltk                                     3.8.1\n",
    "notebook                                 7.0.6\n",
    "notebook_shim                            0.2.3\n",
    "numexpr                                  2.8.4\n",
    "numpy                                    1.25.2\n",
    "oauthlib                                 3.2.2\n",
    "onnxruntime                              1.16.3\n",
    "openai                                   1.3.8\n",
    "opentelemetry-api                        1.21.0\n",
    "opentelemetry-exporter-otlp-proto-common 1.21.0\n",
    "opentelemetry-exporter-otlp-proto-grpc   1.21.0\n",
    "opentelemetry-instrumentation            0.42b0\n",
    "opentelemetry-instrumentation-asgi       0.42b0\n",
    "opentelemetry-instrumentation-fastapi    0.42b0\n",
    "opentelemetry-proto                      1.21.0\n",
    "opentelemetry-sdk                        1.21.0\n",
    "opentelemetry-semantic-conventions       0.42b0\n",
    "opentelemetry-util-http                  0.42b0\n",
    "orjson                                   3.9.10\n",
    "overrides                                7.4.0\n",
    "packaging                                23.2\n",
    "pandas                                   2.0.3\n",
    "pandocfilters                            1.5.0\n",
    "parso                                    0.8.3\n",
    "pexpect                                  4.8.0\n",
    "pickleshare                              0.7.5\n",
    "Pillow                                   9.4.0\n",
    "pip                                      23.2.1\n",
    "platformdirs                             3.10.0\n",
    "posthog                                  3.1.0\n",
    "prometheus-client                        0.14.1\n",
    "prompt-toolkit                           3.0.36\n",
    "protobuf                                 4.25.1\n",
    "psutil                                   5.9.0\n",
    "ptyprocess                               0.7.0\n",
    "pulsar-client                            3.3.0\n",
    "pure-eval                                0.2.2\n",
    "pyasn1                                   0.5.1\n",
    "pyasn1-modules                           0.3.0\n",
    "pycparser                                2.21\n",
    "pydantic                                 2.5.3\n",
    "pydantic_core                            2.14.6\n",
    "pydub                                    0.25.1\n",
    "Pygments                                 2.15.1\n",
    "pyOpenSSL                                23.2.0\n",
    "pyparsing                                3.1.1\n",
    "PyPika                                   0.48.9\n",
    "PySocks                                  1.7.1\n",
    "python-dateutil                          2.8.2\n",
    "python-dotenv                            1.0.0\n",
    "python-json-logger                       2.0.7\n",
    "python-multipart                         0.0.6\n",
    "pytz                                     2022.7\n",
    "PyYAML                                   6.0.1\n",
    "pyzmq                                    25.1.0\n",
    "referencing                              0.30.2\n",
    "regex                                    2023.10.3\n",
    "requests                                 2.31.0\n",
    "requests-oauthlib                        1.3.1\n",
    "rfc3339-validator                        0.1.4\n",
    "rfc3986-validator                        0.1.1\n",
    "rich                                     13.7.0\n",
    "rpds-py                                  0.10.6\n",
    "rsa                                      4.9\n",
    "safetensors                              0.4.1\n",
    "scikit-learn                             1.3.2\n",
    "scipy                                    1.11.4\n",
    "semantic-version                         2.10.0\n",
    "Send2Trash                               1.8.2\n",
    "sentence-transformers                    2.2.2\n",
    "sentencepiece                            0.1.99\n",
    "setuptools                               68.0.0\n",
    "shellingham                              1.5.4\n",
    "six                                      1.16.0\n",
    "sniffio                                  1.2.0\n",
    "soupsieve                                2.5\n",
    "SQLAlchemy                               2.0.23\n",
    "stack-data                               0.2.0\n",
    "starlette                                0.27.0\n",
    "sympy                                    1.11.1\n",
    "tenacity                                 8.2.3\n",
    "terminado                                0.17.1\n",
    "threadpoolctl                            3.2.0\n",
    "tiktoken                                 0.5.2\n",
    "tinycss2                                 1.2.1\n",
    "tokenizers                               0.15.0\n",
    "tomlkit                                  0.12.0\n",
    "toolz                                    0.12.0\n",
    "torch                                    2.0.1\n",
    "torchaudio                               2.0.2\n",
    "torchvision                              0.15.2\n",
    "tornado                                  6.3.3\n",
    "tqdm                                     4.66.1\n",
    "traitlets                                5.7.1\n",
    "transformers                             4.35.2\n",
    "triton                                   2.0.0\n",
    "typer                                    0.9.0\n",
    "typing_extensions                        4.9.0\n",
    "typing-inspect                           0.9.0\n",
    "tzdata                                   2023.3\n",
    "urllib3                                  1.26.16\n",
    "uvicorn                                  0.24.0.post1\n",
    "uvloop                                   0.19.0\n",
    "watchfiles                               0.21.0\n",
    "wcwidth                                  0.2.5\n",
    "webencodings                             0.5.1\n",
    "websocket-client                         0.58.0\n",
    "websockets                               11.0.3\n",
    "wheel                                    0.38.4\n",
    "wrapt                                    1.16.0\n",
    "yarl                                     1.9.4\n",
    "youtube-transcript-api                   0.6.1\n",
    "zipp                                     3.17.0\n",
    "(llamacpp) sankar@sankar-ml:~$ \n",
    "\n",
    "\n",
    "'''\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
